# ESG ë‰´ìŠ¤ ê¸°ë°˜ ì£¼ì‹ ë¶„ì„ ì‹œìŠ¤í…œ v6.5 - ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±° ë²„ì „
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import requests
from bs4 import BeautifulSoup
from tqdm import tqdm
import re
import time
import json
import os
from datetime import datetime, timedelta
from urllib.parse import quote, urljoin
import warnings
from concurrent.futures import ThreadPoolExecutor
import threading
from functools import lru_cache
import pickle
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.stem import WordNetLemmatizer
import random
from fake_useragent import UserAgent
from urllib.parse import quote
import xml.etree.ElementTree as ET

warnings.filterwarnings('ignore')

# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ì•ˆì „í•œ ë°©ì‹)
def safe_nltk_download():
    try:
        nltk.data.find('tokenizers/punkt')
        nltk.data.find('corpora/stopwords')
        nltk.data.find('corpora/wordnet')
    except LookupError:
        try:
            nltk.download('punkt', quiet=True)
            nltk.download('stopwords', quiet=True)
            nltk.download('wordnet', quiet=True)
        except:
            print("âš ï¸ NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤")

safe_nltk_download()

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False



class WebScrapingStockAnalysisSystem:
    """ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ ì£¼ì‹ ë¶„ì„ ì‹œìŠ¤í…œ - ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±° ë²„ì „"""

    def __init__(self, risk_profile='ì¤‘ë¦½'):
        self.data_collector = WebScrapingStockDataCollector()
        self.classifier = WebScrapingStockClassifier()
        self.portfolio_analyzer = WebScrapingPortfolioAnalyzer(risk_profile)
        self.currency_converter = WebScrapingCurrencyConverter()

        print("ğŸš€ ì›¹ í¬ë¡¤ë§ ì£¼ì‹ ë¶„ì„ ì‹œìŠ¤í…œ v6.5 ì´ˆê¸°í™” ì™„ë£Œ (ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±°)")
        print(f"ğŸ“Š ì„¤ì •ëœ íˆ¬ì ì„±í–¥: {risk_profile}")
        print("ğŸŒ ë°ì´í„° ì†ŒìŠ¤: ë„¤ì´ë²„ ê¸ˆìœµ, ì•¼í›„íŒŒì´ë‚¸ìŠ¤ ì›¹í˜ì´ì§€, êµ¬ê¸€ ë‰´ìŠ¤ (ì›¹ í¬ë¡¤ë§)")
        print(f"ğŸ’± ê¸°ì¤€ í†µí™”: USD (í˜„ì¬ í™˜ìœ¨: {self.currency_converter.get_current_rate():.2f} KRW/USD)")
        print("ğŸ­ ê°ì • ë¶„ì„: VADER + TextBlob + ê¸ˆìœµ íŠ¹í™” í‚¤ì›Œë“œ")
        print("ğŸ”§ ESG ê¸°ì¤€: ë‰´ìŠ¤ 1ê°œ+, í‚¤ì›Œë“œ 1ê°œ+, ì¬ë£Œì„± 0.2+ (ì›¹ í¬ë¡¤ë§ ê¸°ì¤€ ì™„í™”)")

    def analyze_portfolio(self, stock_codes, weights=None):
        """í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ì‹¤í–‰"""
        return self.portfolio_analyzer.analyze_portfolio(stock_codes, weights)

    def analyze_single_stock(self, stock_code):
        """ê°œë³„ ì£¼ì‹ ë¶„ì„"""
        print(f"\nğŸ” {stock_code} ê°œë³„ ë¶„ì„ ì‹œì‘...")

        # ë°ì´í„° ìˆ˜ì§‘
        stock_data = self.data_collector.collect_stock_data(stock_code)

        # ë¶„ë¥˜
        classification = self.classifier.classify_stock(stock_data)

        return {
            'stock_data': stock_data,
            'classification': classification
        }

class WebScrapingStockClassifier:
    """ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ ì£¼ì‹ ë¶„ë¥˜ê¸° - ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±° ë²„ì „"""

    def __init__(self):
        # ESG ë¶„ë¥˜ ì„ê³„ê°’ (ì›¹ í¬ë¡¤ë§ì— ë§ê²Œ ì™„í™”)
        self.esg_thresholds = {
            'esg_score_threshold': 0.1,     # 0.2 â†’ 0.1ë¡œ ì™„í™”
            'esg_news_threshold': 1,        # ìµœì†Œ 1ê°œ ë‰´ìŠ¤
            'esg_keyword_threshold': 1,     # ìµœì†Œ 1ê°œ í‚¤ì›Œë“œ
            'minimum_confidence': 0.4,      # 0.5 â†’ 0.4ë¡œ ì™„í™”
            'negative_sentiment_threshold': -0.25,
            'positive_sentiment_threshold': 0.25,
            'materiality_threshold': 0.2    # ì¬ë£Œì„± ê¸°ì¤€ ì™„í™”
        }

        # ë¶„ë¥˜ ê·œì¹™ (ë‹¬ëŸ¬ ê¸°ì¤€)
        self.classification_rules = {
            'size_thresholds': {
                'mega': 100000000000,  # 1000ì–µ ë‹¬ëŸ¬
                'large': 10000000000,  # 100ì–µ ë‹¬ëŸ¬
                'mid': 1000000000,     # 10ì–µ ë‹¬ëŸ¬
                'small': 100000000     # 1ì–µ ë‹¬ëŸ¬
            }
        }

        # ì„¹í„°ë³„ ìŠ¤íƒ€ì¼ ë§¤í•‘
        self.sector_style_mapping = {
            'Technology': 'ê¸°ìˆ ì£¼',
            'Information Technology': 'ê¸°ìˆ ì£¼',
            'Healthcare': 'í—¬ìŠ¤ì¼€ì–´ì£¼',
            'Consumer Cyclical': 'ì†Œë¹„ì¬ì£¼',
            'Financial Services': 'ê¸ˆìœµì£¼',
            'Energy': 'ì—ë„ˆì§€ì£¼',
            'Materials': 'ì†Œì¬ì£¼',
            'Industrials': 'ì‚°ì—…ì¬ì£¼',
            # í•œêµ­ ì„¹í„°
            'ë°˜ë„ì²´': 'ê¸°ìˆ ì£¼',
            'ì „ê¸°ì „ì': 'ê¸°ìˆ ì£¼',
            'ë°”ì´ì˜¤': 'í—¬ìŠ¤ì¼€ì–´ì£¼',
            'ì€í–‰': 'ê¸ˆìœµì£¼',
            'í™”í•™': 'ì†Œì¬ì£¼',
            'ìë™ì°¨': 'ì‚°ì—…ì¬ì£¼'
        }

        print("âœ… ì›¹ í¬ë¡¤ë§ ì£¼ì‹ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±°)")

    def classify_stock(self, stock_data):
        """ì£¼ì‹ ë¶„ë¥˜"""
        esg_analysis = stock_data.get('esg_analysis', {})

        # ESG ë¶„ë¥˜ ìš°ì„  í™•ì¸
        if self._is_esg_stock(esg_analysis):
            return self._classify_as_esg(stock_data, esg_analysis)

        # ì¼ë°˜ ë¶„ë¥˜
        return self._classify_general_stock(stock_data)

    def _is_esg_stock(self, esg_analysis):
        """ESG ì£¼ì‹ ì—¬ë¶€ íŒë‹¨ (ì›¹ í¬ë¡¤ë§ ê¸°ì¤€ ì™„í™”)"""
        esg_score = esg_analysis.get('total_esg_score', 0)
        news_count = esg_analysis.get('esg_news_count', 0)
        keyword_count = esg_analysis.get('esg_keyword_count', 0)

        # ê°ì • ë¶„ì„ ê²°ê³¼
        sentiment_analysis = esg_analysis.get('sentiment_analysis', {})
        esg_quality_decision = esg_analysis.get('esg_quality_decision', 'neutral')
        materiality_score = sentiment_analysis.get('materiality_score', 0.0)

        # ì™„í™”ëœ ESG ì¡°ê±´
        has_esg_keywords = keyword_count >= self.esg_thresholds['esg_keyword_threshold']
        has_esg_news = news_count >= self.esg_thresholds['esg_news_threshold']
        has_sufficient_materiality = materiality_score >= self.esg_thresholds['materiality_threshold']

        # ë¶€ì •ì  ESGëŠ” ì œì™¸
        if esg_quality_decision == 'negative':
            return False

        return has_esg_keywords and has_esg_news and has_sufficient_materiality

    def _classify_as_esg(self, stock_data, esg_analysis):
        """ESG ì£¼ì‹ ë¶„ë¥˜"""
        basic_info = stock_data.get('basic_info', {})
        market_cap_usd = basic_info.get('market_cap_usd', 0)
        size = self._classify_size_usd(market_cap_usd)

        sector = basic_info.get('sector', '')
        sector_style = self._get_sector_style(sector)

        env_count = esg_analysis.get('environmental_count', 0)
        social_count = esg_analysis.get('social_count', 0)
        gov_count = esg_analysis.get('governance_count', 0)

        esg_quality_decision = esg_analysis.get('esg_quality_decision', 'neutral')

        if sector_style:
            if esg_quality_decision == 'positive':
                category = f"{size} {sector_style} ESG+(E:{env_count}/S:{social_count}/G:{gov_count})"
            else:
                category = f"{size} {sector_style} ESG(E:{env_count}/S:{social_count}/G:{gov_count})"
        else:
            category = f"{size} ESGì£¼(E:{env_count}/S:{social_count}/G:{gov_count})"

        return {
            'category': category,
            'size': size,
            'style': f"ESG({env_count}/{social_count}/{gov_count})",
            'sector_style': sector_style,
            'confidence': self._calculate_esg_confidence(esg_analysis),
            'method': 'webscraping_esg_no_api',
            'esg_score': esg_analysis.get('total_esg_score', 0),
            'esg_reason': self._generate_esg_reason(esg_analysis),
            'esg_counts': f"E:{env_count}/S:{social_count}/G:{gov_count}",
            'sentiment_info': {
                'sentiment_score': esg_analysis.get('sentiment_analysis', {}).get('sentiment_score', 0),
                'esg_quality': esg_quality_decision,
                'materiality_score': esg_analysis.get('sentiment_analysis', {}).get('materiality_score', 0)
            }
        }

    def _classify_general_stock(self, stock_data):
        """ì¼ë°˜ ì£¼ì‹ ë¶„ë¥˜"""
        basic_info = stock_data.get('basic_info', {})
        market_cap_usd = basic_info.get('market_cap_usd', 0)
        size = self._classify_size_usd(market_cap_usd)

        sector = basic_info.get('sector', '')
        sector_style = self._get_sector_style(sector)

        if sector_style:
            final_style = sector_style
        else:
            final_style = 'ê°€ì¹˜ì£¼'

        return {
            'category': f"{size} {final_style}",
            'size': size,
            'style': final_style,
            'sector_style': sector_style,
            'confidence': 0.7,
            'method': 'webscraping_general_no_api'
        }

    def _classify_size_usd(self, market_cap_usd):
        """ê·œëª¨ ë¶„ë¥˜"""
        thresholds = self.classification_rules['size_thresholds']

        if market_cap_usd >= thresholds['mega']:
            return 'ì´ˆëŒ€í˜•'
        elif market_cap_usd >= thresholds['large']:
            return 'ëŒ€í˜•'
        elif market_cap_usd >= thresholds['mid']:
            return 'ì¤‘í˜•'
        else:
            return 'ì†Œí˜•'

    def _get_sector_style(self, sector):
        """ì„¹í„° ê¸°ë°˜ ìŠ¤íƒ€ì¼"""
        if not sector:
            return None

        if sector in self.sector_style_mapping:
            return self.sector_style_mapping[sector]

        sector_lower = sector.lower()
        for key, style in self.sector_style_mapping.items():
            if key.lower() in sector_lower:
                return style

        return None

    def _calculate_esg_confidence(self, esg_analysis):
        """ESG ë¶„ë¥˜ ì‹ ë¢°ë„"""
        base_confidence = 0.6

        esg_score = esg_analysis.get('total_esg_score', 0)
        base_confidence += esg_score * 0.2

        news_count = esg_analysis.get('esg_news_count', 0)
        if news_count >= 3:
            base_confidence += 0.1

        return min(base_confidence, 1.0)

    def _generate_esg_reason(self, esg_analysis):
        """ESG ë¶„ë¥˜ ì´ìœ """
        reasons = []

        env_count = esg_analysis.get('environmental_count', 0)
        social_count = esg_analysis.get('social_count', 0)
        gov_count = esg_analysis.get('governance_count', 0)

        if env_count > 0:
            reasons.append(f'í™˜ê²½ í‚¤ì›Œë“œ {env_count}ê°œ')
        if social_count > 0:
            reasons.append(f'ì‚¬íšŒ í‚¤ì›Œë“œ {social_count}ê°œ')
        if gov_count > 0:
            reasons.append(f'ì§€ë°°êµ¬ì¡° í‚¤ì›Œë“œ {gov_count}ê°œ')

        news_count = esg_analysis.get('esg_news_count', 0)
        if news_count > 0:
            reasons.append(f'ESG ë‰´ìŠ¤ {news_count}ê±´')

        return ', '.join(reasons) if reasons else 'ì›¹ í¬ë¡¤ë§ ESG ë¶„ë¥˜'

class WebScrapingInvestmentAdvisor:
    """ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ íˆ¬ì ì œì•ˆ ì‹œìŠ¤í…œ"""

    def __init__(self, risk_profile='ì¤‘ë¦½'):
        self.risk_profile = risk_profile

        # ì´ìƒì  í¬íŠ¸í´ë¦¬ì˜¤ ë¶„í¬ (ê°•í™”ëœ ESG ê¸°ì¤€)
        self.ideal_distributions = {
            'ë³´ìˆ˜': {
                'ëŒ€í˜• ê¸ˆìœµì£¼': 0.15, 'ëŒ€í˜• í•„ìˆ˜ì†Œë¹„ì¬ì£¼': 0.15, 'ì¤‘í˜• ë°°ë‹¹ì£¼': 0.10,
                'ëŒ€í˜• ê¸°ìˆ ì£¼ ESG': 0.20, 'ëŒ€í˜• ìœ í‹¸ë¦¬í‹°ì£¼': 0.10, 'ëŒ€í˜• í—¬ìŠ¤ì¼€ì–´ì£¼': 0.10,
                'ì´ˆëŒ€í˜• ë°°ë‹¹ì£¼': 0.15, 'ì¤‘í˜• ê°€ì¹˜ì£¼': 0.05
            },
            'ì¤‘ë¦½': {
                'ëŒ€í˜• ê¸°ìˆ ì£¼': 0.20, 'ëŒ€í˜• ê¸ˆìœµì£¼': 0.10, 'ì¤‘í˜• ê¸°ìˆ ì£¼': 0.15,
                'ëŒ€í˜• ê¸°ìˆ ì£¼ ESG': 0.15, 'ëŒ€í˜• í—¬ìŠ¤ì¼€ì–´ì£¼': 0.08, 'ì†Œí˜• ì„±ì¥ì£¼': 0.08,
                'ì¤‘í˜• ì†Œì¬ì£¼': 0.07, 'ëŒ€í˜• ì†Œë¹„ì¬ì£¼': 0.07, 'ê¸°íƒ€': 0.10
            },
            'ê³µê²©': {
                'ëŒ€í˜• ê¸°ìˆ ì£¼': 0.25, 'ì¤‘í˜• ê¸°ìˆ ì£¼': 0.20, 'ì†Œí˜• ê¸°ìˆ ì£¼': 0.15,
                'ëŒ€í˜• ê¸°ìˆ ì£¼ ESG': 0.20, 'ì´ˆëŒ€í˜• ê¸°ìˆ ì£¼': 0.15, 'ì¤‘í˜• ì„±ì¥ì£¼': 0.05
            }
        }

        print(f"âœ… ì›¹ í¬ë¡¤ë§ íˆ¬ì ì œì•ˆ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (ì„±í–¥: {risk_profile})")

    def generate_dynamic_ideal_distribution(self, current_distribution):
        """í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ì— ë”°ë¥¸ ë™ì  ì´ìƒì  ë¶„í¬ ìƒì„±"""
        try:
            print(f"ğŸ¯ ë™ì  ì´ìƒì  ë¶„í¬ ìƒì„± ì‹œì‘...")
            print(f"ğŸ“Š ì…ë ¥ëœ í˜„ì¬ ë¶„í¬: {current_distribution}")
            
            # í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ì˜ ì¹´í…Œê³ ë¦¬ë“¤ í™•ì¸
            current_categories = list(current_distribution.keys())
            
            if not current_categories:
                print("âš ï¸ í˜„ì¬ ë¶„í¬ê°€ ë¹„ì–´ìˆìŒ - ê¸°ë³¸ ë¶„í¬ ì‚¬ìš©")
                return self.ideal_distributions.get(self.risk_profile, self.ideal_distributions['ì¤‘ë¦½'])
            
            # ì¹´í…Œê³ ë¦¬ ê°„ì†Œí™” ë§¤í•‘
            simplified_categories = {}
            for category in current_categories:
                # ë³µì¡í•œ ESG ì¹´í…Œê³ ë¦¬ë¥¼ ê°„ë‹¨í•˜ê²Œ ë³€í™˜
                if 'ESG' in category:
                    if 'ê¸°ìˆ ì£¼' in category:
                        simplified_key = 'ëŒ€í˜• ê¸°ìˆ ì£¼ ESG'
                    elif 'ê¸ˆìœµì£¼' in category:
                        simplified_key = 'ëŒ€í˜• ê¸ˆìœµì£¼ ESG'
                    elif 'í—¬ìŠ¤ì¼€ì–´ì£¼' in category:
                        simplified_key = 'ëŒ€í˜• í—¬ìŠ¤ì¼€ì–´ì£¼ ESG'
                    else:
                        simplified_key = 'ê¸°íƒ€ ESG'
                elif 'ê¸°ìˆ ì£¼' in category:
                    if 'ëŒ€í˜•' in category or 'ì´ˆëŒ€í˜•' in category:
                        simplified_key = 'ëŒ€í˜• ê¸°ìˆ ì£¼'
                    elif 'ì¤‘í˜•' in category:
                        simplified_key = 'ì¤‘í˜• ê¸°ìˆ ì£¼'
                    else:
                        simplified_key = 'ì†Œí˜• ê¸°ìˆ ì£¼'
                elif 'ê¸ˆìœµì£¼' in category:
                    simplified_key = 'ëŒ€í˜• ê¸ˆìœµì£¼'
                elif 'í—¬ìŠ¤ì¼€ì–´ì£¼' in category:
                    simplified_key = 'ëŒ€í˜• í—¬ìŠ¤ì¼€ì–´ì£¼'
                elif 'ì†Œì¬ì£¼' in category:
                    simplified_key = 'ì¤‘í˜• ì†Œì¬ì£¼'
                elif 'ì†Œë¹„ì¬ì£¼' in category:
                    simplified_key = 'ëŒ€í˜• ì†Œë¹„ì¬ì£¼'
                elif 'ì„±ì¥ì£¼' in category:
                    simplified_key = 'ì†Œí˜• ì„±ì¥ì£¼'
                else:
                    simplified_key = 'ê¸°íƒ€'
                
                # í˜„ì¬ ë¶„í¬ë¥¼ ê°„ì†Œí™”ëœ í‚¤ë¡œ ì§‘ê³„
                current_weight = current_distribution[category]
                if simplified_key in simplified_categories:
                    simplified_categories[simplified_key] += current_weight
                else:
                    simplified_categories[simplified_key] = current_weight
            
            print(f"ğŸ”„ ê°„ì†Œí™”ëœ í˜„ì¬ ë¶„í¬: {simplified_categories}")
            
            # ê¸°ë³¸ ì´ìƒì  ë¶„í¬ ê°€ì ¸ì˜¤ê¸°
            base_ideal = self.ideal_distributions.get(self.risk_profile, self.ideal_distributions['ì¤‘ë¦½'])
            
            # í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ì— ì¡´ì¬í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë§Œ ì‚¬ìš©í•˜ì—¬ ì´ìƒì  ë¶„í¬ ìƒì„±
            ideal_dist = {}
            
            for simplified_key in simplified_categories.keys():
                if simplified_key in base_ideal:
                    ideal_dist[simplified_key] = base_ideal[simplified_key]
                else:
                    # ê¸°ë³¸ê°’ í• ë‹¹
                    if 'ESG' in simplified_key:
                        ideal_dist[simplified_key] = 0.15
                    elif 'ê¸°ìˆ ì£¼' in simplified_key:
                        ideal_dist[simplified_key] = 0.20
                    elif 'ê¸ˆìœµì£¼' in simplified_key:
                        ideal_dist[simplified_key] = 0.10
                    else:
                        ideal_dist[simplified_key] = 0.08
            
            # ì •ê·œí™” (í•©ê³„ê°€ 1.0ì´ ë˜ë„ë¡)
            total_sum = sum(ideal_dist.values())
            if total_sum > 0:
                ideal_dist = {k: v/total_sum for k, v in ideal_dist.items()}
            
            print(f"âœ… ë™ì  ì´ìƒì  ë¶„í¬ ìƒì„± ì™„ë£Œ: {ideal_dist}")
            return ideal_dist
            
        except Exception as e:
            print(f"âŒ ë™ì  ë¶„í¬ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„í¬ ì‚¬ìš©
            return self.ideal_distributions.get(self.risk_profile, self.ideal_distributions['ì¤‘ë¦½'])

    def _simplify_distribution(self, current_distribution):
        """ë³µì¡í•œ ì¹´í…Œê³ ë¦¬ë¥¼ ê°„ë‹¨í•˜ê²Œ ë³€í™˜"""
        simplified = {}
        
        for category, weight in current_distribution.items():
            # ë³µì¡í•œ ESG ì¹´í…Œê³ ë¦¬ë¥¼ ê°„ë‹¨í•˜ê²Œ ë³€í™˜
            if 'ESG' in category:
                if 'ê¸°ìˆ ì£¼' in category:
                    simple_key = 'ëŒ€í˜• ê¸°ìˆ ì£¼ ESG'
                elif 'ê¸ˆìœµì£¼' in category:
                    simple_key = 'ëŒ€í˜• ê¸ˆìœµì£¼ ESG'
                else:
                    simple_key = 'ê¸°íƒ€ ESG'
            elif 'ê¸°ìˆ ì£¼' in category:
                if 'ëŒ€í˜•' in category or 'ì´ˆëŒ€í˜•' in category:
                    simple_key = 'ëŒ€í˜• ê¸°ìˆ ì£¼'
                elif 'ì¤‘í˜•' in category:
                    simple_key = 'ì¤‘í˜• ê¸°ìˆ ì£¼'
                else:
                    simple_key = 'ì†Œí˜• ê¸°ìˆ ì£¼'
            elif 'ê¸ˆìœµì£¼' in category:
                simple_key = 'ëŒ€í˜• ê¸ˆìœµì£¼'
            elif 'í—¬ìŠ¤ì¼€ì–´ì£¼' in category:
                simple_key = 'ëŒ€í˜• í—¬ìŠ¤ì¼€ì–´ì£¼'
            elif 'ì„±ì¥ì£¼' in category:
                simple_key = 'ì†Œí˜• ì„±ì¥ì£¼'
            elif 'ì†Œì¬ì£¼' in category:
                simple_key = 'ì¤‘í˜• ì†Œì¬ì£¼'
            elif 'ì†Œë¹„ì¬ì£¼' in category:
                simple_key = 'ëŒ€í˜• ì†Œë¹„ì¬ì£¼'
            else:
                simple_key = 'ê¸°íƒ€'
            
            if simple_key in simplified:
                simplified[simple_key] += weight
            else:
                simplified[simple_key] = weight
        
        return simplified

    def generate_investment_recommendations(self, current_distribution, portfolio_analysis):
        """ë™ì  íˆ¬ì ì œì•ˆ ìƒì„±"""
        print(f"\nğŸ¯ íˆ¬ì ì œì•ˆ ìƒì„± ì‹œì‘...")
        print(f"ğŸ“Š ì›ë³¸ í˜„ì¬ ë¶„í¬: {current_distribution}")
        
        # ê°„ì†Œí™”ëœ ë¶„í¬ ìƒì„±
        simplified_current = self._simplify_distribution(current_distribution)
        print(f"ğŸ”„ ê°„ì†Œí™”ëœ í˜„ì¬ ë¶„í¬: {simplified_current}")
        
        # ë™ì  ì´ìƒì  ë¶„í¬ ê³„ì‚°
        ideal_dist = self.generate_dynamic_ideal_distribution(current_distribution)
        
        print(f"ğŸ¯ ì´ìƒì  ë¶„í¬: {ideal_dist}")
        
        recommendations = []
        
        # ê°„ì†Œí™”ëœ ë¶„í¬ì™€ ì´ìƒì  ë¶„í¬ ë¹„êµ
        for category, ideal_weight in ideal_dist.items():
            current_weight = simplified_current.get(category, 0.0)
            difference = ideal_weight - current_weight
            
            print(f"ğŸ“ˆ {category}: í˜„ì¬ {current_weight:.3f} â†’ ì´ìƒ {ideal_weight:.3f} (ì°¨ì´: {difference:.3f})")
            
            if abs(difference) > 0.05:  # 5% ì´ìƒ ì°¨ì´
                priority = self._determine_priority(abs(difference))
                action = 'ëŠ˜ë ¤ì•¼' if difference > 0 else 'ì¤„ì—¬ì•¼'
                
                recommendations.append({
                    'category': category,
                    'action': action,
                    'amount': abs(difference),
                    'priority': priority,
                    'difference': difference
                })
                
                print(f"  â¡ï¸ ì¶”ì²œ: {category} {action} {abs(difference)*100:.1f}% (ìš°ì„ ìˆœìœ„: {priority})")
        
        # ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
        recommendations.sort(key=lambda x: (
            0 if x['priority'] == 'high' else 1 if x['priority'] == 'medium' else 2,
            -x['amount']
        ))
        
        print(f"âœ… ì´ {len(recommendations)}ê°œ íˆ¬ì ì œì•ˆ ìƒì„±")
        return recommendations

    def _determine_priority(self, difference):
        """ìš°ì„ ìˆœìœ„ ê²°ì •"""
        if difference >= 0.15:
            return 'high'
        elif difference >= 0.08:
            return 'medium'
        else:
            return 'low'

    def _assess_news_quality(self, portfolio_analysis):
        """ë‰´ìŠ¤ í’ˆì§ˆ í‰ê°€ ë©”ì„œë“œ ì¶”ê°€"""
        try:
            # í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ì—ì„œ ë‰´ìŠ¤ í’ˆì§ˆ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
            esg_analysis = portfolio_analysis.get('esg_analysis', {})
            esg_ratio = esg_analysis.get('esg_ratio', 0)

            # ê¸°ë³¸ ë‰´ìŠ¤ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            if esg_ratio >= 0.3:
                return 0.8  # ë†’ì€ ESG ë¹„ì¤‘ = ì¢‹ì€ ë‰´ìŠ¤ í’ˆì§ˆ
            elif esg_ratio >= 0.2:
                return 0.6  # ì¤‘ê°„ ESG ë¹„ì¤‘
            else:
                return 0.4  # ë‚®ì€ ESG ë¹„ì¤‘

        except Exception as e:
            print(f"âš ï¸ ë‰´ìŠ¤ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5  # ê¸°ë³¸ê°’

    def format_recommendations(self, recommendations, portfolio_analysis):
        """íˆ¬ì ì œì•ˆ í¬ë§·íŒ…"""
        if not recommendations:
            return "âœ… í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ê°€ ì´ìƒì  ë¶„í¬ì— ê·¼ì ‘í•©ë‹ˆë‹¤."

        output = []
        output.append("ğŸ’¡ ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ íˆ¬ì ì œì•ˆ (ë‹¬ëŸ¬ ê¸°ì¤€, ESG ê¸°ì¤€ ê°•í™”)")
        output.append("-" * 60)
        output.append("")

        # ìš°ì„ ìˆœìœ„ë³„ ê·¸ë£¹í™”
        high_priority = [r for r in recommendations if r['priority'] == 'high']
        medium_priority = [r for r in recommendations if r['priority'] == 'medium']
        low_priority = [r for r in recommendations if r['priority'] == 'low']

        if high_priority:
            output.append("ğŸ”´ ìš°ì„ ìˆœìœ„ ë†’ìŒ:")
            for rec in high_priority:
                emoji = "ğŸ”¥" if rec['amount'] >= 0.15 else "âš ï¸"
                output.append(f" {emoji} {rec['category']} ë¹„ì¤‘ì„ {rec['amount']*100:.1f}% {rec['action']} í•©ë‹ˆë‹¤")
            output.append("")

        if medium_priority:
            output.append("ğŸŸ¡ ìš°ì„ ìˆœìœ„ ë³´í†µ:")
            for rec in medium_priority:
                emoji = "ğŸ’¡" if rec['amount'] >= 0.10 else "ğŸ“Š"
                output.append(f" {emoji} {rec['category']} ë¹„ì¤‘ì„ {rec['amount']*100:.1f}% {rec['action']} í•©ë‹ˆë‹¤")
            output.append("")

        if low_priority:
            output.append("ğŸŸ¢ ìš°ì„ ìˆœìœ„ ë‚®ìŒ:")
            for rec in low_priority:
                output.append(f" ğŸ“ˆ {rec['category']} ë¹„ì¤‘ì„ {rec['amount']*100:.1f}% {rec['action']} í•©ë‹ˆë‹¤")
            output.append("")

        # ì¶”ê°€ ì œì•ˆì‚¬í•­
        esg_analysis = portfolio_analysis.get('esg_analysis', {})
        esg_ratio = esg_analysis.get('esg_ratio', 0)

        if esg_ratio < 0.3:
            output.append("ğŸŒ± ESG íˆ¬ì ë¹„ì¤‘ì„ 30% ì´ìƒìœ¼ë¡œ ëŠ˜ë¦¬ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤")

        news_quality = self._assess_news_quality(portfolio_analysis)
        if news_quality < 0.6:
            output.append("ğŸ’¡ ë” ë§ì€ ë‰´ìŠ¤ ì†ŒìŠ¤ í™•ë³´ í•„ìš”")

        return "\n".join(output)


class WebScrapingPortfolioGrader:
    """ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ë“±ê¸‰ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.currency_converter = WebScrapingCurrencyConverter()

        # ë“±ê¸‰ ê¸°ì¤€
        self.grade_thresholds = {
            'A+': 0.95, 'A': 0.85, 'A-': 0.80,  # ê¸°ì¡´ë³´ë‹¤ 5-10ì  ìƒí–¥
            'B+': 0.75, 'B': 0.70, 'B-': 0.65,
            'C+': 0.60, 'C': 0.55, 'C-': 0.50,
            'D': 0.40, 'F': 0.0
        }

        print("âœ… ì›¹ í¬ë¡¤ë§ í¬íŠ¸í´ë¦¬ì˜¤ ë“±ê¸‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def calculate_comprehensive_score(self, analysis_result):
        """ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        portfolio_analysis = analysis_result['portfolio_analysis']
        stock_results = analysis_result['stock_results']

        # 1. ESG ì ìˆ˜ (40% ê°€ì¤‘ì¹˜)
        esg_score = self._calculate_esg_score(portfolio_analysis, stock_results)

        # 2. ë‰´ìŠ¤ í’ˆì§ˆ ì ìˆ˜ (25% ê°€ì¤‘ì¹˜)
        news_quality_score = self._calculate_news_quality_score(stock_results)

        # 3. ê°ì • ë¶„ì„ ì ìˆ˜ (20% ê°€ì¤‘ì¹˜)
        sentiment_score = self._calculate_sentiment_score(stock_results)

        # 4. í¬íŠ¸í´ë¦¬ì˜¤ ë‹¤ì–‘ì„± ì ìˆ˜ (15% ê°€ì¤‘ì¹˜)
        diversity_score = self._calculate_diversity_score(portfolio_analysis)

        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        comprehensive_score = (
            esg_score * 0.40 +
            news_quality_score * 0.25 +
            sentiment_score * 0.20 +
            diversity_score * 0.15
        )

        return {
            'comprehensive_score': comprehensive_score,
            'esg_score': esg_score,
            'news_quality_score': news_quality_score,
            'sentiment_score': sentiment_score,
            'diversity_score': diversity_score,
            'grade': self._assign_grade(comprehensive_score)
        }

    def _calculate_esg_score(self, portfolio_analysis, stock_results):
        """ESG ì ìˆ˜ ê³„ì‚°"""
        esg_analysis = portfolio_analysis.get('esg_analysis', {})
        esg_ratio = esg_analysis.get('esg_ratio', 0)
        avg_esg_score = esg_analysis.get('average_esg_score', 0)

        # ESG ë¹„ì¤‘ê³¼ í‰ê·  ESG ì ìˆ˜ë¥¼ ê²°í•©
        esg_weight_score = min(esg_ratio / 0.5, 1.0)  # 50% ê¸°ì¤€
        esg_quality_score = avg_esg_score

        return (esg_weight_score * 0.6 + esg_quality_score * 0.4)

    def _calculate_news_quality_score(self, stock_results):
        """ë‰´ìŠ¤ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        total_news = 0
        quality_scores = []

        for result in stock_results.values():
            esg_news = result['raw_data'].get('esg_news', [])
            total_news += len(esg_news)

            if len(esg_news) >= 5:  # 3ê°œ â†’ 5ê°œë¡œ ê°•í™”
                quality_scores.append(0.8)
            elif len(esg_news) >= 3:
                quality_scores.append(0.5)
            elif len(esg_news) >= 1:
                quality_scores.append(0.3)  # 0.5 â†’ 0.3ìœ¼ë¡œ í•˜í–¥
            else:
                quality_scores.append(0.0)  # 0.2 â†’ 0.0ìœ¼ë¡œ í•˜í–¥


        if not quality_scores:
            return 0.0

        avg_quality = sum(quality_scores) / len(quality_scores)
        news_volume_bonus = min(total_news / 20, 0.2)  # 20ê°œ ë‰´ìŠ¤ ê¸°ì¤€

        return min(avg_quality + news_volume_bonus, 1.0)

    def _calculate_sentiment_score(self, stock_results):
        """ê°ì • ë¶„ì„ ì ìˆ˜ ê³„ì‚°"""
        sentiment_scores = []

        for result in stock_results.values():
            esg_analysis = result['raw_data'].get('esg_analysis', {})
            sentiment_analysis = esg_analysis.get('sentiment_analysis', {})

            esg_quality = esg_analysis.get('esg_quality_decision', 'neutral')
            materiality_score = sentiment_analysis.get('materiality_score', 0)

            if esg_quality == 'positive':
                sentiment_scores.append(0.8 + materiality_score * 0.2)
            elif esg_quality == 'negative':
                sentiment_scores.append(0.2)
            else:
                sentiment_scores.append(0.5 + materiality_score * 0.3)

        return sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0.5

    def _calculate_diversity_score(self, portfolio_analysis):
        """í¬íŠ¸í´ë¦¬ì˜¤ ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚°"""
        current_dist = portfolio_analysis.get('current_distribution', {})

        if not current_dist:
            return 0.0

        # ì¹´í…Œê³ ë¦¬ ìˆ˜
        category_count = len(current_dist)
        category_score = min(category_count / 6, 1.0)  # 6ê°œ ì¹´í…Œê³ ë¦¬ ê¸°ì¤€

        # ë¶„í¬ ê· í˜•ë„ (ì§€ë‹ˆ ê³„ìˆ˜ ì—­ìˆ˜)
        weights = list(current_dist.values())
        if weights:
            try:
                gini = self._calculate_gini_coefficient(weights)
                balance_score = 1 - gini
            except Exception as e:
                print(f"âš ï¸ ì§€ë‹ˆ ê³„ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
                balance_score = 0.5  # ê¸°ë³¸ê°’
        else:
            balance_score = 0

        return (category_score * 0.4 + balance_score * 0.6)


    def _calculate_gini_coefficient(self, weights):
        """ì§€ë‹ˆ ê³„ìˆ˜ ê³„ì‚°"""
        if not weights:
            return 1.0

        weights = sorted(weights)
        n = len(weights)
        cumsum = sum((i + 1) * w for i, w in enumerate(weights))

        return (2 * cumsum) / (n * sum(weights)) - (n + 1) / n

    def _assign_grade(self, score):
        """ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰ í• ë‹¹"""
        for grade, threshold in self.grade_thresholds.items():
            if score >= threshold:
                return grade
        return 'F'

    def generate_insights(self, analysis_result, grading_result):
        """ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        portfolio_analysis = analysis_result['portfolio_analysis']
        stock_results = analysis_result['stock_results']

        insights = []
        insights.append("ğŸ’¡ ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ (ë‹¬ëŸ¬ ê¸°ì¤€, ESG ê¸°ì¤€ ê°•í™”)")
        insights.append("=" * 60)

        # í™˜ìœ¨ ì •ë³´
        current_rate = self.currency_converter.get_current_rate()
        insights.append(f"ğŸ’± í˜„ì¬ í™˜ìœ¨: {current_rate:.2f} KRW/USDë¡œ ëª¨ë“  ë¶„ì„ì´ ë‹¬ëŸ¬ ê¸°ì¤€ìœ¼ë¡œ í†µì¼ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ESG ê¸°ì¤€ ì •ë³´
        insights.append("ğŸ”§ ê°•í™”ëœ ESG ê¸°ì¤€ ì ìš©: ë‰´ìŠ¤ 3ê°œ+, í‚¤ì›Œë“œ 3ê°œ+, ì¬ë£Œì„± 0.5+ ê¸°ì¤€")

        # ESG íˆ¬ì ë¹„ì¤‘
        esg_analysis = portfolio_analysis.get('esg_analysis', {})
        esg_ratio = esg_analysis.get('esg_ratio', 0)
        if esg_ratio >= 0.3:
            insights.append(f"ğŸŒ± ESG íˆ¬ì ë¹„ì¤‘ì´ {esg_ratio*100:.0f}% ì´ìƒìœ¼ë¡œ ì§€ì†ê°€ëŠ¥í•œ íˆ¬ì í¬íŠ¸í´ë¦¬ì˜¤ì…ë‹ˆë‹¤.")
        else:
            insights.append(f"âš ï¸ ESG íˆ¬ì ë¹„ì¤‘ì´ {esg_ratio*100:.0f}%ë¡œ 30% ë¯¸ë§Œì…ë‹ˆë‹¤. ì¦ëŒ€ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")

        # ë‰´ìŠ¤ í’ˆì§ˆ
        news_quality = grading_result['news_quality_score']
        if news_quality >= 0.7:
            insights.append(f"ğŸ“° ìš°ìˆ˜í•œ ë‰´ìŠ¤ ë°ì´í„° í’ˆì§ˆ (í’ˆì§ˆ ì ìˆ˜: {news_quality:.2f})")
        elif news_quality >= 0.5:
            insights.append(f"ğŸ“° ì–‘í˜¸í•œ ë‰´ìŠ¤ ë°ì´í„° í’ˆì§ˆ (í’ˆì§ˆ ì ìˆ˜: {news_quality:.2f})")
        else:
            insights.append(f"ğŸ“° ë‰´ìŠ¤ ë°ì´í„° í’ˆì§ˆ ê°œì„  í•„ìš” (í’ˆì§ˆ ì ìˆ˜: {news_quality:.2f})")

        # ê°ì • ë¶„ì„ í’ˆì§ˆ
        sentiment_score = grading_result['sentiment_score']
        if sentiment_score >= 0.7:
            insights.append(f"ğŸ­ ìš°ìˆ˜í•œ ESG ë‰´ìŠ¤ ê°ì • í’ˆì§ˆ (ê°ì • ì ìˆ˜: {sentiment_score:.2f})")
        elif sentiment_score >= 0.5:
            insights.append(f"ğŸ­ ì–‘í˜¸í•œ ESG ë‰´ìŠ¤ ê°ì • í’ˆì§ˆ (ê°ì • ì ìˆ˜: {sentiment_score:.2f})")
        else:
            insights.append(f"ğŸ­ ESG ë‰´ìŠ¤ ê°ì • í’ˆì§ˆ ê°œì„  í•„ìš” (ê°ì • ì ìˆ˜: {sentiment_score:.2f})")

        # ë‰´ìŠ¤ ë°ì´í„° ìˆ˜
        total_news = sum(len(result['raw_data'].get('esg_news', [])) for result in stock_results.values())
        if total_news >= 20:
            insights.append(f"ğŸ” í’ë¶€í•œ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ ({total_news}ê°œ ë‰´ìŠ¤)")
        elif total_news >= 10:
            insights.append(f"ğŸ” ì ì •í•œ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ({total_news}ê°œ ë‰´ìŠ¤)")
        else:
            insights.append(f"ğŸ” ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë¶€ì¡± ({total_news}ê°œ ë‰´ìŠ¤)")

        # ì¢…í•© ë“±ê¸‰
        grade = grading_result['grade']
        comprehensive_score = grading_result['comprehensive_score']

        grade_emoji = {
            'A+': 'ğŸ†', 'A': 'ğŸ¥‡', 'A-': 'ğŸ¥ˆ',
            'B+': 'ğŸ¥‰', 'B': 'ğŸ“ˆ', 'B-': 'ğŸ“Š',
            'C+': 'âš ï¸', 'C': 'âš ï¸', 'C-': 'âš ï¸',
            'D': 'ğŸ”´', 'F': 'âŒ'
        }.get(grade, 'ğŸ“Š')

        grade_description = {
            'A+': 'ìµœìš°ìˆ˜', 'A': 'ìš°ìˆ˜', 'A-': 'ì–‘í˜¸',
            'B+': 'ë³´í†µ', 'B': 'ë³´í†µ', 'B-': 'ë³´í†µ',
            'C+': 'ê°œì„ í•„ìš”', 'C': 'ê°œì„ í•„ìš”', 'C-': 'ê°œì„ í•„ìš”',
            'D': 'ë¶€ì¡±', 'F': 'ë§¤ìš°ë¶€ì¡±'
        }.get(grade, 'ë³´í†µ')

        insights.append(f"{grade_emoji} ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ë“±ê¸‰: {grade} ({grade_description})")
        insights.append(f"ğŸ“Š ì¢…í•© ì ìˆ˜: {comprehensive_score:.2f}/1.00 (ESG ê¸°ì¤€ ê°•í™” + ê°ì • ë¶„ì„ ë°˜ì˜)")

        return "\n".join(insights)


class WebScrapingPortfolioAnalyzer:
    """ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ê¸° - ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±° ë²„ì „"""

    def __init__(self, risk_profile='ì¤‘ë¦½'):
        self.risk_profile = risk_profile
        self.currency_converter = WebScrapingCurrencyConverter()
        self.investment_advisor = WebScrapingInvestmentAdvisor(risk_profile)
        self.portfolio_grader = WebScrapingPortfolioGrader()

        # ì´ìƒì  í¬íŠ¸í´ë¦¬ì˜¤ ë¶„í¬
        self.ideal_distributions = {
            'ë³´ìˆ˜': {
                'ëŒ€í˜• ê¸ˆìœµì£¼': 0.15, 'ëŒ€í˜• í•„ìˆ˜ì†Œë¹„ì¬ì£¼': 0.15, 'ì¤‘í˜• ë°°ë‹¹ì£¼': 0.10,
                'ëŒ€í˜• ê¸°ìˆ ì£¼ ESG': 0.15, 'ëŒ€í˜• ìœ í‹¸ë¦¬í‹°ì£¼': 0.10, 'ëŒ€í˜• í—¬ìŠ¤ì¼€ì–´ì£¼': 0.10,
                'ì´ˆëŒ€í˜• ë°°ë‹¹ì£¼': 0.15, 'ì¤‘í˜• ê°€ì¹˜ì£¼': 0.10
            },
            'ì¤‘ë¦½': {
                'ëŒ€í˜• ê¸°ìˆ ì£¼': 0.20, 'ëŒ€í˜• ê¸ˆìœµì£¼': 0.12, 'ì¤‘í˜• ê¸°ìˆ ì£¼': 0.15,
                'ëŒ€í˜• ê¸°ìˆ ì£¼ ESG': 0.12, 'ëŒ€í˜• í—¬ìŠ¤ì¼€ì–´ì£¼': 0.08, 'ì†Œí˜• ì„±ì¥ì£¼': 0.10,
                'ì¤‘í˜• ì†Œì¬ì£¼': 0.08, 'ëŒ€í˜• ì†Œë¹„ì¬ì£¼': 0.08, 'ê¸°íƒ€': 0.07
            },
            'ê³µê²©': {
                'ëŒ€í˜• ê¸°ìˆ ì£¼': 0.25, 'ì¤‘í˜• ê¸°ìˆ ì£¼': 0.20, 'ì†Œí˜• ê¸°ìˆ ì£¼': 0.15,
                'ëŒ€í˜• ê¸°ìˆ ì£¼ ESG': 0.15, 'ì´ˆëŒ€í˜• ê¸°ìˆ ì£¼': 0.15, 'ì¤‘í˜• ì„±ì¥ì£¼': 0.10
            }
        }

        print(f"âœ… ì›¹ í¬ë¡¤ë§ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ì„±í–¥: {risk_profile}, ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±°)")

    def analyze_portfolio(self, stock_codes, weights=None):
        """í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„"""
        print(f"\nğŸ” {len(stock_codes)}ê°œ ì¢…ëª© ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ì‹œì‘ (ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±°)")
        print("=" * 90)

        # ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ë¥˜
        stock_results = {}

        for i, stock_code in enumerate(stock_codes, 1):
            print(f"\n[{i}/{len(stock_codes)}] {stock_code} ì›¹ í¬ë¡¤ë§ ë¶„ì„ ì¤‘...")

            try:
                data_collector = WebScrapingStockDataCollector()
                stock_data = data_collector.collect_stock_data(stock_code)

                classifier = WebScrapingStockClassifier()
                classification = classifier.classify_stock(stock_data)

                stock_results[stock_code] = {
                    'raw_data': stock_data,
                    'classification': classification
                }

                company_name = stock_data.get('basic_info', {}).get('name', stock_code)
                confidence = classification['confidence']
                market_cap_usd = stock_data.get('basic_info', {}).get('market_cap_usd', 0)

                print(f"âœ… {company_name}: {classification['category']}")
                print(f"   ì‹ ë¢°ë„: {confidence:.2f} | ì‹œê°€ì´ì•¡: ${market_cap_usd:,.0f}")

                if 'ESG' in classification['category']:
                    esg_score = classification.get('esg_score', 0)
                    esg_reason = classification.get('esg_reason', '')
                    print(f"   ESGì ìˆ˜: {esg_score:.2f} | ì‚¬ìœ : {esg_reason}")

            except Exception as e:
                print(f"âŒ {stock_code} ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                stock_results[stock_code] = self._get_default_result(stock_code)

            if i < len(stock_codes):
                print("â³ ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ëŒ€ê¸° ì¤‘...")
                time.sleep(random.uniform(3, 6))

        # í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„
        classifications = {code: result['classification'] for code, result in stock_results.items()}
        portfolio_analysis = self._analyze_portfolio_distribution(classifications, weights)

        # ê¸°ë³¸ ê²°ê³¼ êµ¬ì„±
        result = {
            'stock_results': stock_results,
            'portfolio_analysis': portfolio_analysis,
            'summary': self._generate_summary(stock_results, portfolio_analysis),
            'currency_info': {
                'base_currency': 'USD',
                'exchange_rate': self.currency_converter.get_current_rate()
            }
        }

        # íˆ¬ì ì œì•ˆ ìƒì„± (return ì´ì „ìœ¼ë¡œ ì´ë™)
        try:
            recommendations = self.investment_advisor.generate_investment_recommendations(
                portfolio_analysis['current_distribution'],
                portfolio_analysis
            )
            result['investment_recommendations'] = recommendations
            print("âœ… íˆ¬ì ì œì•ˆ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ íˆ¬ì ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            result['investment_recommendations'] = []

        # ì¢…í•© ë“±ê¸‰ ê³„ì‚° (return ì´ì „ìœ¼ë¡œ ì´ë™)
        try:
            grading_result = self.portfolio_grader.calculate_comprehensive_score(result)
            result['grading_result'] = grading_result
            print("âœ… ì¢…í•© ë“±ê¸‰ ê³„ì‚° ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ì¢…í•© ë“±ê¸‰ ê³„ì‚° ì‹¤íŒ¨: {e}")
            result['grading_result'] = {
                'comprehensive_score': 0.5,
                'grade': 'C',
                'esg_score': 0.5,
                'news_quality_score': 0.5,
                'sentiment_score': 0.5,
                'diversity_score': 0.5
            }

        return result  # ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ í›„ return


    def _analyze_portfolio_distribution(self, classifications, weights):
        """í¬íŠ¸í´ë¦¬ì˜¤ ë¶„í¬ ë¶„ì„"""
        companies = list(classifications.keys())
        if weights is None:
            weights = {company: 1.0/len(companies) for company in companies}
        elif isinstance(weights, list):
            weights = {company: weight for company, weight in zip(companies, weights)}

        # í˜„ì¬ ë¶„í¬
        current_dist = {}
        for company, classification in classifications.items():
            category = classification['category']
            weight = weights[company]
            current_dist[category] = current_dist.get(category, 0) + weight

        # ESG ë¶„ì„
        esg_analysis = self._analyze_esg_portfolio(classifications)

        return {
            'current_distribution': current_dist,
            'esg_analysis': esg_analysis,
            'overall_score': {'overall': 0.7}  # ê¸°ë³¸ ì ìˆ˜
        }

    def _analyze_esg_portfolio(self, classifications):
        """ESG í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„"""
        total_stocks = len(classifications)
        esg_stocks = 0
        total_esg_score = 0

        for classification in classifications.values():
            if 'ESG' in classification.get('category', ''):
                esg_stocks += 1
                total_esg_score += classification.get('esg_score', 0)

        esg_ratio = esg_stocks / total_stocks if total_stocks > 0 else 0
        avg_esg_score = total_esg_score / esg_stocks if esg_stocks > 0 else 0

        return {
            'esg_stock_count': esg_stocks,
            'esg_ratio': esg_ratio,
            'average_esg_score': avg_esg_score
        }

    def _generate_summary(self, stock_results, portfolio_analysis):
        """ìš”ì•½ ìƒì„±"""
        total_stocks = len(stock_results)
        confidences = [result['classification']['confidence'] for result in stock_results.values()]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0

        return {
            'total_stocks': total_stocks,
            'average_confidence': avg_confidence,
            'portfolio_score': 0.7,
            'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

    def _get_default_result(self, stock_code):
        """ê¸°ë³¸ ê²°ê³¼"""
        return {
            'raw_data': {
                'stock_code': stock_code,
                'basic_info': {'name': stock_code, 'market_cap_usd': 0},
                'esg_analysis': {'total_esg_score': 0.0, 'esg_news_count': 0}
            },
            'classification': {
                'category': 'ì¤‘í˜• ê°€ì¹˜ì£¼',
                'confidence': 0.3,
                'method': 'default'
            }
        }

# ë¦¬í¬íŠ¸ ì¶œë ¥ í•¨ìˆ˜ (ê°„ì†Œí™” ë²„ì „)
def print_analysis_report(analysis_result):
    """ë¶„ì„ ë¦¬í¬íŠ¸ ì¶œë ¥ (íˆ¬ì ì œì•ˆ ë° ë“±ê¸‰ í¬í•¨)"""
    print("\n" + "=" * 90)
    print("ğŸ“‹ ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ ESG í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ë¦¬í¬íŠ¸ v6.5")
    print("=" * 90)

    # ê¸°ì¡´ ê°œë³„ ì¢…ëª© ë¶„ì„ ì¶œë ¥...
    print("\nğŸ” ê°œë³„ ì¢…ëª© ë¶„ì„ ê²°ê³¼")
    print("-" * 60)

    for stock_code, result in analysis_result['stock_results'].items():
        classification = result['classification']
        basic_info = result['raw_data'].get('basic_info', {})
        company_name = basic_info.get('name', stock_code)
        market_cap_usd = basic_info.get('market_cap_usd', 0)

        print(f"\nğŸ“ˆ {company_name} ({stock_code})")
        print(f" ë¶„ë¥˜: {classification['category']}")
        print(f" ì‹ ë¢°ë„: {classification['confidence']:.2f}")
        print(f" ì‹œê°€ì´ì•¡: ${market_cap_usd:,.0f}")

    # ESG ë¶„ì„ ì¶œë ¥
    esg_analysis = analysis_result['portfolio_analysis']['esg_analysis']
    print(f"\nğŸŒ± ESG íˆ¬ì ë¶„ì„")
    print("-" * 60)
    print(f" ESG ì¢…ëª© ìˆ˜: {esg_analysis['esg_stock_count']}ê°œ")
    print(f" ESG ë¹„ì¤‘: {esg_analysis['esg_ratio']*100:.1f}%")
    print(f" í‰ê·  ESG ì ìˆ˜: {esg_analysis['average_esg_score']:.2f}")

    # íˆ¬ì ì œì•ˆ ì¶œë ¥
    if 'investment_recommendations' in analysis_result:
        try:
            recommendations = analysis_result['investment_recommendations']
            portfolio_analysis = analysis_result['portfolio_analysis']

            advisor = WebScrapingInvestmentAdvisor()
            recommendation_text = advisor.format_recommendations(recommendations, portfolio_analysis)
            print(f"\n{recommendation_text}")
        except Exception as e:
            print(f"\nâš ï¸ íˆ¬ì ì œì•ˆ ì¶œë ¥ ì‹¤íŒ¨: {e}")

    # ì¢…í•© ë“±ê¸‰ ë° ì¸ì‚¬ì´íŠ¸ ì¶œë ¥
    if 'grading_result' in analysis_result:
        try:
            grader = WebScrapingPortfolioGrader()
            insights = grader.generate_insights(analysis_result, analysis_result['grading_result'])
            print(f"\n{insights}")
        except Exception as e:
            print(f"\nâš ï¸ ì¢…í•© ë“±ê¸‰ ì¶œë ¥ ì‹¤íŒ¨: {e}")

    # ìš”ì•½ ì¶œë ¥
    summary = analysis_result['summary']
    print(f"\nğŸ“‹ ë¶„ì„ ìš”ì•½")
    print("-" * 60)
    print(f" ì´ ì¢…ëª© ìˆ˜: {summary['total_stocks']}ê°œ")
    print(f" í‰ê·  ì‹ ë¢°ë„: {summary['average_confidence']:.2f}")
    print(f" ë¶„ì„ ì¼ì‹œ: {summary['analysis_timestamp']}")



class WebScrapingCurrencyConverter:
    """ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ í™˜ìœ¨ ë³€í™˜ê¸° - ê°œì„ ëœ ë²„ì „"""

    def __init__(self):
        self.exchange_rates = {}
        self.last_update = None
        self.session = requests.Session()

        # ë‹¤ì–‘í•œ User-Agent í—¤ë” ì„¤ì •
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0'
        ]

        self._update_headers()
        self.update_exchange_rates()
        print("âœ… ì›¹ í¬ë¡¤ë§ í™˜ìœ¨ ë³€í™˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    def _update_headers(self):
        """í—¤ë” ì—…ë°ì´íŠ¸"""
        user_agent = random.choice(self.user_agents)
        self.session.headers.update({
            'User-Agent': user_agent,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'max-age=0'
        })

    def update_exchange_rates(self):
        """ì›¹ í¬ë¡¤ë§ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ ì—…ë°ì´íŠ¸ - ê°œì„ ëœ ë²„ì „"""
        print("ğŸ’± í™˜ìœ¨ ì •ë³´ í¬ë¡¤ë§ ì‹œì‘...")

        # ë°©ë²• 1: ë„¤ì´ë²„ ê¸ˆìœµ ë©”ì¸ í˜ì´ì§€ì—ì„œ USD/KRW í™˜ìœ¨ ê°€ì ¸ì˜¤ê¸°
        if self._get_rate_from_naver_main():
            return

        # ë°©ë²• 2: ë„¤ì´ë²„ ê¸ˆìœµ í™˜ìœ¨ ì „ìš© í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        if self._get_rate_from_naver_exchange():
            return

        # ë°©ë²• 3: ë„¤ì´ë²„ ê¸ˆìœµ ìƒì„¸ í™˜ìœ¨ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        if self._get_rate_from_naver_detail():
            return

        # ë°©ë²• 4: ìµœì¢… ë°±ì—… - ê¸°ë³¸ê°’ ì‚¬ìš©
        self._use_default_rate()

    def _get_rate_from_naver_main(self):
        """ë„¤ì´ë²„ ê¸ˆìœµ ë©”ì¸ í˜ì´ì§€ì—ì„œ í™˜ìœ¨ ê°€ì ¸ì˜¤ê¸°"""
        try:
            url = "https://finance.naver.com/marketindex/"
            response = self.session.get(url, timeout=15)

            if response.status_code != 200:
                print(f"âš ï¸ ë„¤ì´ë²„ ë©”ì¸ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨: {response.status_code}")
                return False

            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            # ë°©ë²• 1-1: exchangeListì—ì„œ USD ì°¾ê¸°
            usd_element = soup.select_one('ul#exchangeList span.value')
            if usd_element:
                rate_text = usd_element.get_text().strip().replace(',', '')
                try:
                    current_rate = float(rate_text)
                    self.exchange_rates['USD_KRW'] = current_rate
                    self.last_update = datetime.now()
                    print(f"ğŸ’± í˜„ì¬ USD/KRW í™˜ìœ¨: {current_rate:.2f} (ë„¤ì´ë²„ ë©”ì¸)")
                    return True
                except ValueError:
                    pass

            # ë°©ë²• 1-2: ë‹¤ë¥¸ ì„ íƒì ì‹œë„
            rate_elements = soup.select('span.value')
            for element in rate_elements:
                rate_text = element.get_text().strip().replace(',', '')
                try:
                    current_rate = float(rate_text)
                    if 1000 <= current_rate <= 2000:  # í•©ë¦¬ì ì¸ USD/KRW í™˜ìœ¨ ë²”ìœ„
                        self.exchange_rates['USD_KRW'] = current_rate
                        self.last_update = datetime.now()
                        print(f"ğŸ’± í˜„ì¬ USD/KRW í™˜ìœ¨: {current_rate:.2f} (ë„¤ì´ë²„ ë©”ì¸ ëŒ€ì•ˆ)")
                        return True
                except ValueError:
                    continue

            return False

        except Exception as e:
            print(f"âš ï¸ ë„¤ì´ë²„ ë©”ì¸ í˜ì´ì§€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return False

    def _get_rate_from_naver_exchange(self):
        """ë„¤ì´ë²„ ê¸ˆìœµ í™˜ìœ¨ ì „ìš© í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            url = "https://finance.naver.com/marketindex/exchangeList.naver"
            response = self.session.get(url, timeout=15)

            if response.status_code != 200:
                print(f"âš ï¸ ë„¤ì´ë²„ í™˜ìœ¨ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨: {response.status_code}")
                return False

            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            # í…Œì´ë¸”ì—ì„œ USD í–‰ ì°¾ê¸°
            rows = soup.find_all('tr')
            for row in rows:
                columns = row.find_all('td')
                if len(columns) >= 2:
                    # ì²« ë²ˆì§¸ ì—´ì—ì„œ í†µí™”ëª… í™•ì¸
                    currency_cell = columns[0]
                    if currency_cell and 'USD' in currency_cell.get_text():
                        # ë‘ ë²ˆì§¸ ì—´ì—ì„œ í™˜ìœ¨ ê°’ ì¶”ì¶œ
                        rate_cell = columns[1]
                        if rate_cell:
                            rate_text = rate_cell.get_text().strip().replace(',', '')
                            try:
                                current_rate = float(rate_text)
                                self.exchange_rates['USD_KRW'] = current_rate
                                self.last_update = datetime.now()
                                print(f"ğŸ’± í˜„ì¬ USD/KRW í™˜ìœ¨: {current_rate:.2f} (ë„¤ì´ë²„ í™˜ìœ¨ í˜ì´ì§€)")
                                return True
                            except ValueError:
                                continue

            return False

        except Exception as e:
            print(f"âš ï¸ ë„¤ì´ë²„ í™˜ìœ¨ í˜ì´ì§€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return False

    def _get_rate_from_naver_detail(self):
        """ë„¤ì´ë²„ ê¸ˆìœµ USD ìƒì„¸ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            url = "https://finance.naver.com/marketindex/exchangeDetail.naver?marketindexCd=FX_USDKRW"
            response = self.session.get(url, timeout=15)

            if response.status_code != 200:
                print(f"âš ï¸ ë„¤ì´ë²„ USD ìƒì„¸ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨: {response.status_code}")
                return False

            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            # í˜„ì¬ í™˜ìœ¨ ì¶”ì¶œ
            rate_element = soup.select_one('p.no_today')
            if rate_element:
                rate_text = rate_element.get_text().strip()
                # ìˆ«ìë§Œ ì¶”ì¶œ (ì˜ˆ: "1,379.00ì›" -> "1379.00")
                rate_numbers = re.findall(r'[\d,]+\.?\d*', rate_text)
                if rate_numbers:
                    rate_clean = rate_numbers[0].replace(',', '')
                    try:
                        current_rate = float(rate_clean)
                        self.exchange_rates['USD_KRW'] = current_rate
                        self.last_update = datetime.now()
                        print(f"ğŸ’± í˜„ì¬ USD/KRW í™˜ìœ¨: {current_rate:.2f} (ë„¤ì´ë²„ USD ìƒì„¸)")
                        return True
                    except ValueError:
                        pass

            return False

        except Exception as e:
            print(f"âš ï¸ ë„¤ì´ë²„ USD ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return False

    def _use_default_rate(self):
        """ê¸°ë³¸ í™˜ìœ¨ ì‚¬ìš©"""
        try:
            # ì‹¤ì‹œê°„ í™˜ìœ¨ API ëŒ€ì•ˆ ì‹œë„ (ë¬´ë£Œ)
            url = "https://api.exchangerate-api.com/v4/latest/USD"
            response = self.session.get(url, timeout=10)

            if response.status_code == 200:
                data = response.json()
                krw_rate = data.get('rates', {}).get('KRW')
                if krw_rate:
                    self.exchange_rates['USD_KRW'] = krw_rate
                    self.last_update = datetime.now()
                    print(f"ğŸ’± í˜„ì¬ USD/KRW í™˜ìœ¨: {krw_rate:.2f} (ExchangeRate API)")
                    return

        except Exception as e:
            print(f"âš ï¸ ì™¸ë¶€ í™˜ìœ¨ API ì‹¤íŒ¨: {e}")

        # ìµœì¢… ë°±ì—… - ê³ ì •ê°’ ì‚¬ìš©
        self.exchange_rates['USD_KRW'] = 1350.0
        self.last_update = datetime.now()
        print("âš ï¸ ê¸°ë³¸ í™˜ìœ¨ ì‚¬ìš©: 1,350 KRW/USD")

    def safe_request(self, url, max_retries=3):
        """ì•ˆì „í•œ ì›¹ ìš”ì²­"""
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    self._update_headers()
                    time.sleep(random.uniform(2, 5))

                response = self.session.get(url, timeout=15)
                if response.status_code == 200:
                    return response
                elif response.status_code == 403:
                    print(f"âš ï¸ ì ‘ê·¼ ê±°ë¶€ (403) - ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                    time.sleep(random.uniform(5, 10))
                else:
                    print(f"âš ï¸ HTTP {response.status_code} - ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                    time.sleep(random.uniform(3, 6))

            except requests.exceptions.RequestException as e:
                print(f"âš ï¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e} - ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                time.sleep(random.uniform(5, 10))

        return None

    def krw_to_usd(self, krw_amount):
        """ì›í™”ë¥¼ ë‹¬ëŸ¬ë¡œ ë³€í™˜"""
        if not krw_amount or krw_amount <= 0:
            return 0

        # 30ë¶„ë§ˆë‹¤ í™˜ìœ¨ ì—…ë°ì´íŠ¸
        if (self.last_update and
            (datetime.now() - self.last_update).total_seconds() > 1800):
            print("ğŸ”„ í™˜ìœ¨ ì •ë³´ ì—…ë°ì´íŠ¸ ì¤‘...")
            self.update_exchange_rates()

        usd_krw_rate = self.exchange_rates.get('USD_KRW', 1350.0)
        return krw_amount / usd_krw_rate

    def usd_to_krw(self, usd_amount):
        """ë‹¬ëŸ¬ë¥¼ ì›í™”ë¡œ ë³€í™˜"""
        if not usd_amount or usd_amount <= 0:
            return 0

        # 30ë¶„ë§ˆë‹¤ í™˜ìœ¨ ì—…ë°ì´íŠ¸
        if (self.last_update and
            (datetime.now() - self.last_update).total_seconds() > 1800):
            print("ğŸ”„ í™˜ìœ¨ ì •ë³´ ì—…ë°ì´íŠ¸ ì¤‘...")
            self.update_exchange_rates()

        usd_krw_rate = self.exchange_rates.get('USD_KRW', 1350.0)
        return usd_amount * usd_krw_rate

    def get_current_rate(self):
        """í˜„ì¬ í™˜ìœ¨ ë°˜í™˜"""
        return self.exchange_rates.get('USD_KRW', 1350.0)

    def get_rate_info(self):
        """í™˜ìœ¨ ì •ë³´ ìƒì„¸ ë°˜í™˜"""
        return {
            'rate': self.get_current_rate(),
            'last_update': self.last_update.strftime('%Y-%m-%d %H:%M:%S') if self.last_update else 'Unknown',
            'source': 'Naver Finance Web Scraping'
        }

    def force_update(self):
        """ê°•ì œ í™˜ìœ¨ ì—…ë°ì´íŠ¸"""
        print("ğŸ”„ í™˜ìœ¨ ê°•ì œ ì—…ë°ì´íŠ¸ ì‹¤í–‰...")
        self.update_exchange_rates()
        return self.get_rate_info()

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    # í™˜ìœ¨ ë³€í™˜ê¸° í…ŒìŠ¤íŠ¸
    converter = WebScrapingCurrencyConverter()

    print(f"\nğŸ“Š í˜„ì¬ í™˜ìœ¨ ì •ë³´:")
    rate_info = converter.get_rate_info()
    print(f"í™˜ìœ¨: {rate_info['rate']:.2f} KRW/USD")
    print(f"ì—…ë°ì´íŠ¸: {rate_info['last_update']}")
    print(f"ì†ŒìŠ¤: {rate_info['source']}")

    print(f"\nğŸ’° ë³€í™˜ í…ŒìŠ¤íŠ¸:")
    print(f"1,000,000 KRW = ${converter.krw_to_usd(1000000):,.2f} USD")
    print(f"$1,000 USD = {converter.usd_to_krw(1000):,.0f} KRW")


class WebScrapingYahooFinanceCollector:
    """ì•¼í›„íŒŒì´ë‚¸ìŠ¤ ì›¹ í¬ë¡¤ë§ ìˆ˜ì§‘ê¸° - ê°œì„ ëœ ë²„ì „ (API ì œê±°)"""

    def __init__(self):
        self.session = requests.Session()

        # ë‹¤ì–‘í•œ User-Agent í—¤ë” ì„¤ì •
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0'
        ]

        self._update_headers()
        print("âœ… ì•¼í›„íŒŒì´ë‚¸ìŠ¤ ì›¹ í¬ë¡¤ë§ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ê°œì„ ëœ ë²„ì „)")

    def _update_headers(self):
        """í—¤ë” ì—…ë°ì´íŠ¸"""
        user_agent = random.choice(self.user_agents)
        self.session.headers.update({
            'User-Agent': user_agent,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'max-age=0'
        })

    def safe_request(self, url, max_retries=3):
        """ì•ˆì „í•œ ì›¹ ìš”ì²­"""
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    self._update_headers()
                    time.sleep(random.uniform(3, 8))

                response = self.session.get(url, timeout=15)
                if response.status_code == 200:
                    return response
                elif response.status_code == 403:
                    print(f"âš ï¸ ì ‘ê·¼ ê±°ë¶€ (403) - ëŒ€ê¸° í›„ ì¬ì‹œë„... {attempt + 1}/{max_retries}")
                    time.sleep(random.uniform(8, 15))
                elif response.status_code == 429:
                    print(f"âš ï¸ ìš”ì²­ í•œë„ ì´ˆê³¼ (429) - ëŒ€ê¸° ì¤‘... {attempt + 1}/{max_retries}")
                    time.sleep(random.uniform(15, 25))
                else:
                    print(f"âš ï¸ HTTP {response.status_code} - ì¬ì‹œë„... {attempt + 1}/{max_retries}")
                    time.sleep(random.uniform(5, 10))

            except requests.exceptions.RequestException as e:
                print(f"âš ï¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e} - ì¬ì‹œë„ ì¤‘... {attempt + 1}/{max_retries}")
                time.sleep(random.uniform(8, 15))

        return None

    def scrape_stock_info(self, symbol):
        """ì•¼í›„íŒŒì´ë‚¸ìŠ¤ì—ì„œ ì£¼ì‹ ì •ë³´ í¬ë¡¤ë§ - ì„¹í„° ì •ë³´ ê°•í™” ë²„ì „"""
        try:
            # ë©”ì¸ í˜ì´ì§€ì—ì„œ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
            url = f"https://finance.yahoo.com/quote/{symbol}"
            response = self.safe_request(url)

            if not response:
                print(f"âš ï¸ {symbol} ë©”ì¸ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨")
                return self._get_empty_stock_info(symbol)

            soup = BeautifulSoup(response.text, 'html.parser')
            company_name = self._extract_company_name(soup, symbol)
            sector = self._extract_sector(soup)

            # ì„¹í„° ì •ë³´ê°€ ì—†ìœ¼ë©´ Profile í˜ì´ì§€ì—ì„œ ì¶”ê°€ ì‹œë„
            if not sector:
                print(f"ğŸ” {symbol} Profile í˜ì´ì§€ì—ì„œ ì„¹í„° ì •ë³´ ì¬ì‹œë„...")
                sector = self._try_profile_page_for_sector(symbol)

            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            stock_info = {
                'symbol': symbol,
                'name': company_name,
                'sector': sector,
                'industry': self._extract_industry(soup),
                'market_cap': self._extract_market_cap(soup),
                'current_price': self._extract_current_price(soup),
                'financial_data': self._extract_financial_data(soup),
                'description': self._extract_description(soup)
            }

            print(f"âœ… {symbol} ì •ë³´ í¬ë¡¤ë§ ì™„ë£Œ: {stock_info['name']} | ì„¹í„°: {stock_info['sector']} | ì‹œê°€ì´ì•¡: ${stock_info['market_cap']:,.0f}")
            return stock_info

        except Exception as e:
            print(f"âŒ {symbol} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return self._get_empty_stock_info(symbol)

    def _try_profile_page_for_sector(self, symbol):
        """Profile í˜ì´ì§€ì—ì„œ ì„¹í„° ì •ë³´ ì¬ì‹œë„"""
        try:
            profile_url = f"https://finance.yahoo.com/quote/{symbol}/profile"
            response = self.safe_request(profile_url)

            if response:
                soup = BeautifulSoup(response.text, 'html.parser')
                sector = self._extract_sector(soup)
                if sector:
                    print(f"âœ… Profile í˜ì´ì§€ì—ì„œ ì„¹í„° ì¶”ì¶œ ì„±ê³µ: {sector}")
                    return sector

            return ""
        except Exception as e:
            print(f"âš ï¸ Profile í˜ì´ì§€ ì„¹í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    def _extract_sector(self, soup):
        """ëŒ€í­ ê°œì„ ëœ ì„¹í„° ì •ë³´ ì¶”ì¶œ"""
        try:
            # ë°©ë²• 1: ìƒˆë¡œìš´ ì•¼í›„íŒŒì´ë‚¸ìŠ¤ êµ¬ì¡° ì„ íƒìë“¤ (2024-2025ë…„ ë²„ì „)
            enhanced_selectors = [
                # ìµœì‹  ì•¼í›„íŒŒì´ë‚¸ìŠ¤ ì„¹í„° ì„ íƒìë“¤
                '[data-test="SECTOR-value"]',
                'td[data-test="SECTOR-value"]',
                'span[data-test="SECTOR-value"]',
                '[data-field="sector"]',

                # Profile í˜ì´ì§€ ì„¹í„° ì„ íƒìë“¤
                'span:contains("Sector") + span',
                'span:contains("Sector(s)") + span',
                'td:contains("Sector") + td',
                'th:contains("Sector") + td',

                # í…Œì´ë¸” êµ¬ì¡° ê¸°ë°˜ ì„ íƒìë“¤
                'tr:contains("Sector") td:last-child',
                'tr:contains("Sector(s)") td:last-child',

                # ìƒˆë¡œìš´ êµ¬ì¡° ì„ íƒìë“¤
                '.Fw\\(600\\):contains("Technology")',
                '.Fw\\(600\\):contains("Healthcare")',
                '.Fw\\(600\\):contains("Financial")',
                '.Fw\\(600\\):contains("Consumer")',
                '.Fw\\(600\\):contains("Energy")',
                '.Fw\\(600\\):contains("Materials")',
                '.Fw\\(600\\):contains("Industrials")',
                '.Fw\\(600\\):contains("Utilities")',
                '.Fw\\(600\\):contains("Real Estate")',
                '.Fw\\(600\\):contains("Communication")',

                # ëŒ€ì•ˆ ì„ íƒìë“¤
                'span.Fw\\(600\\)',
                'td.Fw\\(600\\)',
                '.company-info .sector',
                '.profile-section span'
            ]

            for selector in enhanced_selectors:
                try:
                    elements = soup.select(selector)
                    for element in elements:
                        sector_text = element.get_text().strip()
                        if self._is_valid_sector(sector_text):
                            print(f"âœ… ì„¹í„° ì •ë³´ ì¶”ì¶œ ì„±ê³µ: {sector_text} (ì„ íƒì: {selector})")
                            return sector_text
                except Exception as e:
                    continue

            # ë°©ë²• 2: í…ìŠ¤íŠ¸ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì„¹í„° ì°¾ê¸°
            sector_from_text = self._extract_sector_from_text_patterns(soup)
            if sector_from_text:
                return sector_from_text

            # ë°©ë²• 3: Profile í˜ì´ì§€ì—ì„œ ì¶”ê°€ í¬ë¡¤ë§
            sector_from_profile = self._extract_sector_from_profile_page(soup)
            if sector_from_profile:
                return sector_from_profile

            # ë°©ë²• 4: JSON ë°ì´í„°ì—ì„œ ì„¹í„° ì¶”ì¶œ
            sector_from_json = self._extract_sector_from_json_data(soup)
            if sector_from_json:
                return sector_from_json

            print("âš ï¸ ëª¨ë“  ë°©ë²•ìœ¼ë¡œ ì„¹í„° ì¶”ì¶œ ì‹¤íŒ¨")
            return ""

        except Exception as e:
            print(f"âš ï¸ ì„¹í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return ""

    def _is_valid_sector(self, sector_text):
        """ìœ íš¨í•œ ì„¹í„°ì¸ì§€ í™•ì¸"""
        if not sector_text or len(sector_text) < 3 or len(sector_text) > 50:
            return False

        # ì•Œë ¤ì§„ ì„¹í„° ëª©ë¡
        known_sectors = [
            'Technology', 'Healthcare', 'Financial Services', 'Consumer Cyclical',
            'Consumer Defensive', 'Energy', 'Materials', 'Industrials', 'Utilities',
            'Real Estate', 'Communication Services', 'Basic Materials',
            'Information Technology', 'Health Care', 'Financials', 'Consumer Staples',
            'Consumer Discretionary', 'Telecommunication Services'
        ]

        # ì •í™•íˆ ë§¤ì¹­ë˜ëŠ” ì„¹í„°
        if sector_text in known_sectors:
            return True

        # ë¶€ë¶„ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
        sector_lower = sector_text.lower()
        for known in known_sectors:
            if known.lower() in sector_lower or sector_lower in known.lower():
                return True

        # ì„¹í„° í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
        sector_keywords = ['technology', 'healthcare', 'financial', 'consumer', 'energy',
                          'materials', 'industrial', 'utilities', 'real estate', 'communication']

        for keyword in sector_keywords:
            if keyword in sector_lower:
                return True

        return False

    def _extract_sector_from_text_patterns(self, soup):
        """í…ìŠ¤íŠ¸ íŒ¨í„´ì—ì„œ ì„¹í„° ì¶”ì¶œ"""
        try:
            page_text = soup.get_text()

            # ì„¹í„° íŒ¨í„´ ë§¤ì¹­
            sector_patterns = [
                r'Sector[:\s]*([A-Za-z\s&]+?)(?:\s*Industry|\s*Full Time|\s*Market Cap|\n|$)',
                r'Sector\(s\)[:\s]*([A-Za-z\s&]+?)(?:\s*Industry|\s*Full Time|\n|$)',
                r'(?:Sector|SECTOR)[:\s]*([A-Za-z\s&]+?)(?:\s*[A-Z][a-z]|\n|$)',
            ]

            for pattern in sector_patterns:
                matches = re.findall(pattern, page_text, re.IGNORECASE | re.MULTILINE)
                for match in matches:
                    cleaned_sector = match.strip()
                    if self._is_valid_sector(cleaned_sector):
                        print(f"âœ… í…ìŠ¤íŠ¸ íŒ¨í„´ì—ì„œ ì„¹í„° ì¶”ì¶œ: {cleaned_sector}")
                        return cleaned_sector

            return None
        except:
            return None

    def _extract_sector_from_profile_page(self, soup):
        """Profile í˜ì´ì§€ êµ¬ì¡°ì—ì„œ ì„¹í„° ì¶”ì¶œ"""
        try:
            # Profile í˜ì´ì§€ì˜ íŠ¹ë³„í•œ êµ¬ì¡° ì°¾ê¸°
            profile_sections = soup.find_all(['section', 'div'], class_=re.compile(r'profile|company|summary'))

            for section in profile_sections:
                # ì„¹í„° ê´€ë ¨ í…ìŠ¤íŠ¸ ì°¾ê¸°
                sector_elements = section.find_all(text=re.compile(r'Sector', re.IGNORECASE))

                for element in sector_elements:
                    parent = element.parent
                    if parent:
                        # ë‹¤ìŒ í˜•ì œ ìš”ì†Œë“¤ì—ì„œ ì„¹í„° ê°’ ì°¾ê¸°
                        next_elements = parent.find_next_siblings(['span', 'td', 'div'])
                        for next_elem in next_elements[:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ í™•ì¸
                            sector_text = next_elem.get_text().strip()
                            if self._is_valid_sector(sector_text):
                                print(f"âœ… Profile í˜ì´ì§€ì—ì„œ ì„¹í„° ì¶”ì¶œ: {sector_text}")
                                return sector_text

            return None
        except:
            return None

    def _extract_sector_from_json_data(self, soup):
        """JSON ë°ì´í„°ì—ì„œ ì„¹í„° ì¶”ì¶œ"""
        try:
            # ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ì—ì„œ JSON ë°ì´í„° ì°¾ê¸°
            script_tags = soup.find_all('script')

            for script in script_tags:
                script_content = script.string
                if script_content and ('sector' in script_content.lower() or 'quoteSummary' in script_content):
                    try:
                        # JSON ë°ì´í„° ì¶”ì¶œ ì‹œë„
                        json_patterns = [
                            r'quoteSummary["\']:\s*({.+?})\s*[,}]',
                            r'"sector":\s*"([^"]+)"',
                            r'"sectorKey":\s*"([^"]+)"',
                            r'"sectorDisp":\s*"([^"]+)"'
                        ]

                        for pattern in json_patterns:
                            matches = re.findall(pattern, script_content, re.IGNORECASE)
                            for match in matches:
                                if isinstance(match, str) and self._is_valid_sector(match):
                                    print(f"âœ… JSONì—ì„œ ì„¹í„° ì¶”ì¶œ: {match}")
                                    return match
                                elif isinstance(match, str):
                                    try:
                                        # JSON íŒŒì‹± ì‹œë„
                                        json_data = json.loads(match)
                                        sector_paths = [
                                            ['result', 0, 'summaryProfile', 'sector'],
                                            ['result', 0, 'assetProfile', 'sector'],
                                            ['result', 0, 'quoteType', 'sector'],
                                            ['sector'],
                                            ['sectorKey'],
                                            ['sectorDisp']
                                        ]

                                        for path in sector_paths:
                                            try:
                                                current = json_data
                                                for key in path:
                                                    current = current[key]
                                                if current and isinstance(current, str) and self._is_valid_sector(current):
                                                    print(f"âœ… JSON ê²½ë¡œì—ì„œ ì„¹í„° ì¶”ì¶œ: {current}")
                                                    return current
                                            except:
                                                continue
                                    except json.JSONDecodeError:
                                        continue

                    except Exception as e:
                        continue

            return None
        except:
            return None

    def _extract_industry(self, soup):
        """ì‚°ì—… ì •ë³´ ì¶”ì¶œ"""
        try:
            selectors = [
                '[data-test="INDUSTRY-value"]',
                'td[data-test="INDUSTRY-value"]',
                'span[data-test="INDUSTRY-value"]',
                '[data-field="industry"]'
            ]

            for selector in selectors:
                element = soup.select_one(selector)
                if element:
                    industry = element.get_text().strip()
                    if industry and len(industry) < 50:
                        return industry

            # ëŒ€ì•ˆ ë°©ë²•: Industry í…ìŠ¤íŠ¸ ê²€ìƒ‰
            industry_elements = soup.find_all(text=re.compile(r'Industry', re.IGNORECASE))
            for element in industry_elements:
                parent = element.parent
                if parent:
                    value_element = parent.find_next(['td', 'span', 'div'])
                    if value_element:
                        industry_text = value_element.get_text().strip()
                        if industry_text and len(industry_text) < 50:
                            return industry_text

            return ""
        except:
            return ""

    def _extract_company_name(self, soup, symbol):
        """ëŒ€í­ ê°œì„ ëœ íšŒì‚¬ëª… ì¶”ì¶œ"""
        try:
            # ë°©ë²• 1: ìƒˆë¡œìš´ ì•¼í›„íŒŒì´ë‚¸ìŠ¤ êµ¬ì¡° ì„ íƒìë“¤
            enhanced_selectors = [
                # 2024-2025ë…„ ì•¼í›„íŒŒì´ë‚¸ìŠ¤ ìƒˆ êµ¬ì¡°
                'h1[data-field="symbol"]',
                'h1.D\\(ib\\).Fz\\(18px\\)',
                '[data-test="qsp-header"] h1',
                'h1.C\\(\\$c-fuji-grey-k\\)',
                'section[data-test="qsp-header"] h1',

                # ë©”íƒ€ íƒœê·¸ì—ì„œ ì¶”ì¶œ
                'meta[property="og:title"]',
                'meta[name="title"]',

                # ì œëª© íƒœê·¸ì—ì„œ ì¶”ì¶œ (ì •ì œ í•„ìš”)
                'title',

                # ëŒ€ì•ˆ ì„ íƒìë“¤
                'div[data-test="qsp-header"] h1',
                '.D\\(ib\\).Fz\\(18px\\)',
                'h1.Fw\\(b\\)',
                'h1'
            ]

            for selector in enhanced_selectors:
                try:
                    if selector.startswith('meta'):
                        element = soup.select_one(selector)
                        if element:
                            content = element.get('content', '').strip()
                            if content:
                                # ë©”íƒ€ íƒœê·¸ì—ì„œ íšŒì‚¬ëª… ì •ì œ
                                name = self._clean_company_name_from_meta(content, symbol)
                                if name and name != symbol and len(name) > 1:
                                    return name
                    else:
                        element = soup.select_one(selector)
                        if element:
                            name = element.get_text().strip()
                            # íšŒì‚¬ëª… ì •ì œ
                            name = self._clean_company_name(name, symbol)
                            if name and name != symbol and len(name) > 1:
                                return name
                except Exception as e:
                    continue

            # ë°©ë²• 2: JSON ë°ì´í„°ì—ì„œ ì¶”ì¶œ
            company_name = self._extract_name_from_json_data(soup, symbol)
            if company_name:
                return company_name

            # ë°©ë²• 3: í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ë§¤ì¹­
            company_name = self._extract_name_from_text_patterns(soup, symbol)
            if company_name:
                return company_name

            # ë°©ë²• 4: ëŒ€ì²´ API ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
            company_name = self._get_name_from_yahoo_api(symbol)
            if company_name:
                return company_name

            return symbol

        except Exception as e:
            print(f"âš ï¸ íšŒì‚¬ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return symbol

    def _clean_company_name_from_meta(self, content, symbol):
        """ë©”íƒ€ íƒœê·¸ì—ì„œ íšŒì‚¬ëª… ì •ì œ"""
        try:
            # "Apple Inc. (AAPL) Stock Price, News, Quote & History - Yahoo Finance" í˜•íƒœ
            if '(' in content and ')' in content:
                # ê´„í˜¸ ì•ë¶€ë¶„ ì¶”ì¶œ
                name = content.split('(')[0].strip()
                # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
                name = re.sub(r'\s+(Stock|Price|News|Quote|History|Yahoo|Finance).*', '', name, flags=re.IGNORECASE)
                name = re.sub(r'\s*-\s*.*', '', name)  # - ì´í›„ ì œê±°
                return name.strip()

            # ë‹¤ë¥¸ íŒ¨í„´ë“¤
            patterns = [
                r'^([^-]+)\s*-',  # - ì•ë¶€ë¶„
                r'^([^|]+)\s*\|',  # | ì•ë¶€ë¶„
                r'^([^:]+)\s*:',   # : ì•ë¶€ë¶„
            ]

            for pattern in patterns:
                match = re.search(pattern, content)
                if match:
                    name = match.group(1).strip()
                    name = re.sub(r'\s+(Stock|Price|News|Quote|History).*', '', name, flags=re.IGNORECASE)
                    if len(name) > 1 and name != symbol:
                        return name

            return None
        except:
            return None

    def _clean_company_name(self, name, symbol):
        """íšŒì‚¬ëª… ì •ì œ"""
        try:
            if not name:
                return None

            # ì‹¬ë³¼ê³¼ ê´„í˜¸ ì œê±°
            name = re.sub(r'\([^)]*\)', '', name).strip()

            # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
            unwanted_patterns = [
                r'\s*-\s*Yahoo Finance.*',
                r'\s*\|\s*Yahoo Finance.*',
                r'\s*:\s*Yahoo Finance.*',
                r'\s*Stock.*',
                r'\s*Quote.*',
                r'\s*News.*',
                r'\s*Price.*',
                r'\s*Chart.*'
            ]

            for pattern in unwanted_patterns:
                name = re.sub(pattern, '', name, flags=re.IGNORECASE)

            # ê³µë°± ì •ë¦¬
            name = re.sub(r'\s+', ' ', name).strip()

            # ìœ íš¨ì„± ê²€ì‚¬
            if len(name) > 1 and name.lower() != symbol.lower() and 'yahoo' not in name.lower():
                return name

            return None
        except:
            return None

    def _extract_name_from_json_data(self, soup, symbol):
        """JSON ë°ì´í„°ì—ì„œ íšŒì‚¬ëª… ì¶”ì¶œ"""
        try:
            # ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ì—ì„œ JSON ë°ì´í„° ì°¾ê¸°
            script_tags = soup.find_all('script')

            for script in script_tags:
                script_content = script.string
                if script_content and 'quoteSummary' in script_content:
                    try:
                        # JSON ë°ì´í„° ì¶”ì¶œ ì‹œë„
                        json_match = re.search(r'quoteSummary["\']:\s*({.+?})\s*[,}]', script_content)
                        if json_match:
                            json_data = json.loads(json_match.group(1))

                            # ë‹¤ì–‘í•œ ê²½ë¡œì—ì„œ íšŒì‚¬ëª… ì°¾ê¸°
                            name_paths = [
                                ['result', 0, 'quoteType', 'longName'],
                                ['result', 0, 'quoteType', 'shortName'],
                                ['result', 0, 'price', 'longName'],
                                ['result', 0, 'price', 'shortName'],
                                ['result', 0, 'summaryProfile', 'longName'],
                            ]

                            for path in name_paths:
                                try:
                                    current = json_data
                                    for key in path:
                                        current = current[key]
                                    if current and isinstance(current, str) and len(current) > 1:
                                        cleaned_name = self._clean_company_name(current, symbol)
                                        if cleaned_name:
                                            return cleaned_name
                                except:
                                    continue

                    except json.JSONDecodeError:
                        continue

            return None
        except:
            return None

    def _extract_name_from_text_patterns(self, soup, symbol):
        """í…ìŠ¤íŠ¸ íŒ¨í„´ì—ì„œ íšŒì‚¬ëª… ì¶”ì¶œ"""
        try:
            page_text = soup.get_text()

            # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ íšŒì‚¬ëª… ì°¾ê¸°
            patterns = [
                rf'{symbol}\s*-\s*([^-|]+?)(?:\s*-|\s*\||$)',
                rf'({symbol}[^-|]+?)(?:\s*-|\s*\||$)',
                rf'([A-Z][a-zA-Z\s&.,]+(?:Inc|Corp|Ltd|LLC|Company|Co)\.?)\s*\({symbol}\)',
            ]

            for pattern in patterns:
                matches = re.findall(pattern, page_text, re.IGNORECASE)
                for match in matches:
                    if isinstance(match, tuple):
                        match = match[0] if match else ''

                    cleaned_name = self._clean_company_name(match, symbol)
                    if cleaned_name and len(cleaned_name) > 3:
                        return cleaned_name

            return None
        except:
            return None

    def _get_name_from_yahoo_api(self, symbol):
        """ì•¼í›„ ê²€ìƒ‰ APIì—ì„œ íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°"""
        try:
            import urllib.request
            import json

            url = f'https://query2.finance.yahoo.com/v1/finance/search?q={symbol}'

            # í—¤ë” ì„¤ì •
            req = urllib.request.Request(url)
            req.add_header('User-Agent', random.choice(self.user_agents))

            with urllib.request.urlopen(req, timeout=10) as response:
                content = response.read()
                data = json.loads(content.decode('utf8'))

                quotes = data.get('quotes', [])
                for quote in quotes:
                    if quote.get('symbol') == symbol:
                        # longName ë˜ëŠ” shortName ì‚¬ìš©
                        name = quote.get('longName') or quote.get('shortName')
                        if name:
                            cleaned_name = self._clean_company_name(name, symbol)
                            if cleaned_name:
                                return cleaned_name

            return None
        except Exception as e:
            print(f"âš ï¸ ì•¼í›„ APIì—ì„œ íšŒì‚¬ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def _extract_market_cap(self, soup):
        """ê°œì„ ëœ ì‹œê°€ì´ì•¡ ì¶”ì¶œ"""
        try:
            selectors = [
                '[data-test="MARKET_CAP-value"]',
                'td[data-test="MARKET_CAP-value"]',
                'span[data-test="MARKET_CAP-value"]',
                '[data-field="marketCap"]'
            ]

            for selector in selectors:
                element = soup.select_one(selector)
                if element:
                    market_cap_text = element.get_text().strip()
                    parsed_cap = self._parse_market_cap_improved(market_cap_text)
                    if parsed_cap > 0:
                        return parsed_cap

            # ëŒ€ì•ˆ ë°©ë²•: Market Cap í…ìŠ¤íŠ¸ ê²€ìƒ‰
            market_cap_elements = soup.find_all(text=re.compile(r'Market Cap', re.IGNORECASE))
            for element in market_cap_elements:
                parent = element.parent
                if parent:
                    value_element = parent.find_next(['td', 'span', 'div'])
                    if value_element:
                        market_cap_text = value_element.get_text().strip()
                        parsed_cap = self._parse_market_cap_improved(market_cap_text)
                        if parsed_cap > 0:
                            return parsed_cap

            return 0
        except:
            return 0

    def _parse_market_cap_improved(self, market_cap_text):
        """ê°œì„ ëœ ì‹œê°€ì´ì•¡ íŒŒì‹±"""
        try:
            if not market_cap_text:
                return 0

            # í…ìŠ¤íŠ¸ ì •ë¦¬
            market_cap_text = market_cap_text.replace(',', '').replace('$', '').strip()

            # íŒ¨í„´ ë§¤ì¹­ (ìš°ì„ ìˆœìœ„ ìˆœ)
            patterns = [
                (r'([0-9.]+)\s*T', 1_000_000_000_000),    # ì¡° (Trillion)
                (r'([0-9.]+)\s*B', 1_000_000_000),        # ì‹­ì–µ (Billion)
                (r'([0-9.]+)\s*M', 1_000_000),            # ë°±ë§Œ (Million)
                (r'([0-9.]+)\s*K', 1_000),                # ì²œ (Thousand)
            ]

            for pattern, multiplier in patterns:
                match = re.search(pattern, market_cap_text, re.IGNORECASE)
                if match:
                    number = float(match.group(1))
                    result = int(number * multiplier)
                    # í•©ë¦¬ì ì¸ ë²”ìœ„ ì²´í¬
                    if 1_000_000 <= result <= 10_000_000_000_000:  # 1ë°±ë§Œ ~ 10ì¡° ë‹¬ëŸ¬
                        return result

            # ë‹¨ìˆœ ìˆ«ìì¸ ê²½ìš°
            numbers = re.findall(r'[0-9.]+', market_cap_text)
            if numbers:
                number = float(numbers[0])
                if 1_000_000 <= number <= 10_000_000_000_000:
                    return int(number)

            return 0

        except Exception as e:
            print(f"âš ï¸ ì‹œê°€ì´ì•¡ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return 0

    def _extract_current_price(self, soup):
        """í˜„ì¬ ì£¼ê°€ ì¶”ì¶œ"""
        try:
            selectors = [
                'fin-streamer[data-field="regularMarketPrice"]',
                '[data-test="qsp-price"]',
                '[data-field="regularMarketPrice"]',
                '.Fw\\(b\\).Fz\\(36px\\)'
            ]

            for selector in selectors:
                element = soup.select_one(selector)
                if element:
                    price_text = element.get('value') or element.get_text()
                    if price_text:
                        try:
                            price = float(price_text.replace(',', '').replace('$', ''))
                            if 0.01 <= price <= 100000:  # í•©ë¦¬ì ì¸ ì£¼ê°€ ë²”ìœ„
                                return price
                        except:
                            continue

            return 0
        except:
            return 0

    def _extract_financial_data(self, soup):
        """ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ"""
        try:
            financial_data = {}

            indicators = {
                'PE_RATIO': 'pe_ratio',
                'PEG_RATIO': 'peg_ratio',
                'PRICE_TO_BOOK': 'pb_ratio',
                'DIVIDEND_AND_YIELD': 'dividend_yield',
                'EPS_RATIO': 'eps',
                'BETA': 'beta'
            }

            for yahoo_key, our_key in indicators.items():
                try:
                    element = soup.select_one(f'[data-test="{yahoo_key}-value"]')
                    if element:
                        value_text = element.get_text().strip()
                        financial_data[our_key] = self._parse_financial_value(value_text)
                except:
                    financial_data[our_key] = 0

            return financial_data
        except:
            return {}

    def _parse_financial_value(self, value_text):
        """ì¬ë¬´ ê°’ íŒŒì‹±"""
        try:
            if not value_text or value_text in ['N/A', '--', '']:
                return 0

            if '%' in value_text:
                return float(value_text.replace('%', '')) / 100

            value_text = value_text.replace(',', '').replace('$', '')
            numbers = re.findall(r'[\d.]+', value_text)

            if numbers:
                return float(numbers[0])

            return 0
        except:
            return 0

    def _extract_description(self, soup):
        """íšŒì‚¬ ì„¤ëª… ì¶”ì¶œ"""
        try:
            selectors = [
                '[data-test="qsp-profile"] p',
                '.company-description p',
                '.profile-section p'
            ]

            for selector in selectors:
                element = soup.select_one(selector)
                if element:
                    description = element.get_text().strip()
                    if description and len(description) > 50:
                        return description[:300]

            return ""
        except:
            return ""

    def scrape_korean_stock_info(self, stock_code):
        """í•œêµ­ ì£¼ì‹ ì •ë³´ í¬ë¡¤ë§ - ëŒ€í­ ê°œì„ ëœ ë²„ì „"""
        try:
            # ë°©ë²• 1: ë„¤ì´ë²„ ê¸ˆìœµ ë©”ì¸ í˜ì´ì§€
            stock_info = self._scrape_from_naver_main(stock_code)
            if stock_info and stock_info.get('market_cap_krw', 0) > 0:
                return stock_info

            # ë°©ë²• 2: ë„¤ì´ë²„ ê¸ˆìœµ ê¸°ì—…ì •ë³´ í˜ì´ì§€
            stock_info = self._scrape_from_naver_company(stock_code)
            if stock_info and stock_info.get('market_cap_krw', 0) > 0:
                return stock_info

            # ë°©ë²• 3: ì•¼í›„íŒŒì´ë‚¸ìŠ¤ í•œêµ­ ì£¼ì‹ (.KS)
            stock_info = self._scrape_from_yahoo_kr(stock_code)
            if stock_info and stock_info.get('market_cap_krw', 0) > 0:
                return stock_info

            # ë°©ë²• 4: ìˆ˜ë™ ë°ì´í„°ë² ì´ìŠ¤ (ì£¼ìš” ì¢…ëª©)
            stock_info = self._get_manual_korean_data(stock_code)
            if stock_info:
                return stock_info

            print(f"âš ï¸ {stock_code} ëª¨ë“  í¬ë¡¤ë§ ë°©ë²• ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ì‚¬ìš©")
            return self._get_empty_korean_stock_info(stock_code)

        except Exception as e:
            print(f"âŒ {stock_code} í•œêµ­ ì£¼ì‹ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return self._get_empty_korean_stock_info(stock_code)

    def _scrape_from_naver_main(self, stock_code):
        """ë„¤ì´ë²„ ê¸ˆìœµ ë©”ì¸ í˜ì´ì§€ì—ì„œ í¬ë¡¤ë§"""
        try:
            url = f"https://finance.naver.com/item/main.naver?code={stock_code}"
            response = self.safe_request(url)

            if not response:
                return None

            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            # íšŒì‚¬ëª… ì¶”ì¶œ
            company_name = self._extract_korean_company_name_improved(soup, stock_code)

            # ì„¹í„° ì¶”ì¶œ
            sector = self._extract_korean_sector_improved(soup)

            # ì‹œê°€ì´ì•¡ ì¶”ì¶œ (ê°œì„ ëœ ë°©ë²•)
            market_cap_krw = self._extract_korean_market_cap_improved(soup, stock_code)

            # í˜„ì¬ê°€ ì¶”ì¶œ
            current_price_krw = self._extract_korean_current_price_improved(soup)

            # ì¬ë¬´ ë°ì´í„°
            financial_data = self._extract_korean_financial_data_improved(soup)

            if market_cap_krw > 0:
                print(f"âœ… {company_name} ë„¤ì´ë²„ ë©”ì¸ì—ì„œ í¬ë¡¤ë§ ì„±ê³µ (ì‹œê°€ì´ì•¡: {market_cap_krw:,.0f}ì›)")

                return {
                    'symbol': stock_code,
                    'name': company_name,
                    'sector': sector,
                    'industry': '',
                    'market_cap_krw': market_cap_krw,
                    'current_price_krw': current_price_krw,
                    'financial_data': financial_data,
                    'description': '',
                    'source': 'naver_main'
                }

            return None

        except Exception as e:
            print(f"âš ï¸ ë„¤ì´ë²„ ë©”ì¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return None

    def _scrape_from_naver_company(self, stock_code):
        """ë„¤ì´ë²„ ê¸ˆìœµ ê¸°ì—…ì •ë³´ í˜ì´ì§€ì—ì„œ í¬ë¡¤ë§"""
        try:
            url = f"https://finance.naver.com/item/coinfo.naver?code={stock_code}"
            response = self.safe_request(url)

            if not response:
                return None

            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            # ê¸°ì—… ê°œìš” í…Œì´ë¸”ì—ì„œ ì‹œê°€ì´ì•¡ ì°¾ê¸°
            tables = soup.find_all('table')
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    for i, cell in enumerate(cells):
                        if 'ì‹œê°€ì´ì•¡' in cell.get_text():
                            # ë‹¤ìŒ ì…€ì—ì„œ ê°’ ì¶”ì¶œ
                            if i + 1 < len(cells):
                                market_cap_text = cells[i + 1].get_text().strip()
                                market_cap_krw = self._parse_korean_market_cap_improved(market_cap_text)

                                if market_cap_krw > 0:
                                    company_name = self._extract_korean_company_name_improved(soup, stock_code)

                                    print(f"âœ… {company_name} ë„¤ì´ë²„ ê¸°ì—…ì •ë³´ì—ì„œ í¬ë¡¤ë§ ì„±ê³µ (ì‹œê°€ì´ì•¡: {market_cap_krw:,.0f}ì›)")

                                    return {
                                        'symbol': stock_code,
                                        'name': company_name,
                                        'sector': '',
                                        'industry': '',
                                        'market_cap_krw': market_cap_krw,
                                        'current_price_krw': 0,
                                        'financial_data': {},
                                        'description': '',
                                        'source': 'naver_company'
                                    }

            return None

        except Exception as e:
            print(f"âš ï¸ ë„¤ì´ë²„ ê¸°ì—…ì •ë³´ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return None

    def _scrape_from_yahoo_kr(self, stock_code):
        """ì•¼í›„íŒŒì´ë‚¸ìŠ¤ í•œêµ­ ì£¼ì‹ì—ì„œ í¬ë¡¤ë§"""
        try:
            # í•œêµ­ ì£¼ì‹ì€ .KS ì ‘ë¯¸ì‚¬ í•„ìš”
            yahoo_symbol = f"{stock_code}.KS"
            url = f"https://finance.yahoo.com/quote/{yahoo_symbol}"

            response = self.safe_request(url)
            if not response:
                return None

            soup = BeautifulSoup(response.text, 'html.parser')

            # ì‹œê°€ì´ì•¡ ì¶”ì¶œ
            market_cap_usd = self._extract_market_cap(soup)

            if market_cap_usd > 0:
                # ë‹¬ëŸ¬ë¥¼ ì›í™”ë¡œ ë³€í™˜ (ëŒ€ëµì ì¸ í™˜ìœ¨ ì‚¬ìš©)
                market_cap_krw = market_cap_usd * 1350  # ì„ì‹œ í™˜ìœ¨

                company_name = self._extract_company_name(soup, stock_code)

                print(f"âœ… {company_name} ì•¼í›„íŒŒì´ë‚¸ìŠ¤ KSì—ì„œ í¬ë¡¤ë§ ì„±ê³µ (ì‹œê°€ì´ì•¡: {market_cap_krw:,.0f}ì›)")

                return {
                    'symbol': stock_code,
                    'name': company_name,
                    'sector': self._extract_sector(soup),
                    'industry': '',
                    'market_cap_krw': int(market_cap_krw),
                    'current_price_krw': 0,
                    'financial_data': {},
                    'description': '',
                    'source': 'yahoo_kr'
                }

            return None

        except Exception as e:
            print(f"âš ï¸ ì•¼í›„íŒŒì´ë‚¸ìŠ¤ KS í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return None

    def _get_manual_korean_data(self, stock_code):
        """ì£¼ìš” í•œêµ­ ì£¼ì‹ ìˆ˜ë™ ë°ì´í„°ë² ì´ìŠ¤"""
        manual_data = {
            '096770': {  # SKì´ë…¸ë² ì´ì…˜
                'name': 'SKì´ë…¸ë² ì´ì…˜',
                'sector': 'ì„ìœ ì™€ê°€ìŠ¤',
                'market_cap_krw': 13_670_000_000_000,  # 13.67ì¡°ì› (2025ë…„ ê¸°ì¤€)
                'description': 'ì„ìœ ì •ì œ, í™”í•™, ìœ¤í™œìœ  ì‚¬ì—…ì„ ì˜ìœ„í•˜ëŠ” ì¢…í•© ì—ë„ˆì§€í™”í•™ ê¸°ì—…'
            },
            '304780': {  # í¬ìŠ¤ì½”í™€ë”©ìŠ¤
                'name': 'í¬ìŠ¤ì½”í™€ë”©ìŠ¤',
                'sector': 'ì² ê°•',
                'market_cap_krw': 25_000_000_000_000,  # ì•½ 25ì¡°ì›
                'description': 'ì² ê°• ì œì¡° ë° ê´€ë ¨ ì‚¬ì—…ì„ ì˜ìœ„í•˜ëŠ” ì§€ì£¼íšŒì‚¬'
            },
            '000810': {  # ì‚¼ì„±í™”ì¬
                'name': 'ì‚¼ì„±í™”ì¬',
                'sector': 'ë³´í—˜',
                'market_cap_krw': 18_500_000_000_000,  # ì•½ 18.5ì¡°ì›
                'description': 'ì†í•´ë³´í—˜ì—…ì„ ì£¼ë ¥ìœ¼ë¡œ í•˜ëŠ” ì¢…í•©ê¸ˆìœµì„œë¹„ìŠ¤ ê¸°ì—…'
            },
            '005930': {  # ì‚¼ì„±ì „ì
                'name': 'ì‚¼ì„±ì „ì',
                'sector': 'ë°˜ë„ì²´',
                'market_cap_krw': 400_000_000_000_000,  # ì•½ 400ì¡°ì›
                'description': 'ë°˜ë„ì²´, ìŠ¤ë§ˆíŠ¸í°, ë””ìŠ¤í”Œë ˆì´ ë“±ì„ ì œì¡°í•˜ëŠ” ê¸€ë¡œë²Œ IT ê¸°ì—…'
            }
        }

        if stock_code in manual_data:
            data = manual_data[stock_code]
            print(f"âœ… {data['name']} ìˆ˜ë™ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ ì œê³µ (ì‹œê°€ì´ì•¡: {data['market_cap_krw']:,.0f}ì›)")

            return {
                'symbol': stock_code,
                'name': data['name'],
                'sector': data['sector'],
                'industry': '',
                'market_cap_krw': data['market_cap_krw'],
                'current_price_krw': 0,
                'financial_data': {},
                'description': data['description'],
                'source': 'manual_database'
            }

        return None

    def _extract_korean_company_name_improved(self, soup, stock_code):
        """ê°œì„ ëœ í•œêµ­ ì£¼ì‹ íšŒì‚¬ëª… ì¶”ì¶œ"""
        try:
            # ë°©ë²• 1: ë„¤ì´ë²„ ê¸ˆìœµ í‘œì¤€ ì„ íƒì
            selectors = [
                '.wrap_company h2 a',
                '.wrap_company h2',
                'h2.h_company a',
                '.company_info h2',
                'title'
            ]

            for selector in selectors:
                element = soup.select_one(selector)
                if element:
                    name = element.get_text().strip()
                    # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
                    name = re.sub(r'\s*:\s*ë„¤ì´ë²„.*', '', name)
                    name = re.sub(r'\([^)]*\)', '', name).strip()
                    if name and len(name) > 1 and name != stock_code:
                        return name

            return stock_code
        except:
            return stock_code

    def _extract_korean_sector_improved(self, soup):
        """ê°œì„ ëœ í•œêµ­ ì£¼ì‹ ì„¹í„° ì¶”ì¶œ"""
        try:
            # ë°©ë²• 1: ì—…ì¢… ë§í¬ì—ì„œ ì¶”ì¶œ
            sector_links = soup.find_all('a', href=re.compile(r'sise_group'))
            for link in sector_links:
                sector_text = link.get_text().strip()
                if sector_text and len(sector_text) < 30:
                    return sector_text

            # ë°©ë²• 2: í…Œì´ë¸”ì—ì„œ ì—…ì¢… ì •ë³´ ì°¾ê¸°
            tables = soup.find_all('table')
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    if 'ì—…ì¢…' in row.get_text():
                        cells = row.find_all(['td', 'th'])
                        for cell in cells:
                            text = cell.get_text().strip()
                            if text and 'ì—…ì¢…' not in text and len(text) < 30:
                                return text

            return ""
        except:
            return ""

    def _extract_korean_market_cap_improved(self, soup, stock_code):
        """ëŒ€í­ ê°œì„ ëœ í•œêµ­ ì£¼ì‹ ì‹œê°€ì´ì•¡ ì¶”ì¶œ"""
        try:
            # ë°©ë²• 1: ë„¤ì´ë²„ ê¸ˆìœµ ìƒˆë¡œìš´ êµ¬ì¡°
            market_cap_selectors = [
                'dd.num',
                '.today .num',
                '.market_cap .num',
                'em.num',
                '.blind',
                'td.num'
            ]

            for selector in market_cap_selectors:
                elements = soup.select(selector)
                for element in elements:
                    # ë¶€ëª¨ ìš”ì†Œì—ì„œ "ì‹œê°€ì´ì•¡" í…ìŠ¤íŠ¸ í™•ì¸
                    parent_text = ""
                    current = element.parent
                    for _ in range(3):  # 3ë‹¨ê³„ê¹Œì§€ ë¶€ëª¨ í™•ì¸
                        if current:
                            parent_text += current.get_text()
                            current = current.parent
                        else:
                            break

                    if "ì‹œê°€ì´ì•¡" in parent_text:
                        market_cap_text = element.get_text().strip()
                        parsed_cap = self._parse_korean_market_cap_improved(market_cap_text)
                        if parsed_cap > 0:
                            return parsed_cap

            # ë°©ë²• 2: í…Œì´ë¸” êµ¬ì¡°ì—ì„œ ì°¾ê¸°
            tables = soup.find_all('table')
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    if "ì‹œê°€ì´ì•¡" in row.get_text():
                        cells = row.find_all(['td', 'th'])
                        for cell in cells:
                            cell_text = cell.get_text().strip()
                            if cell_text and "ì‹œê°€ì´ì•¡" not in cell_text:
                                parsed_cap = self._parse_korean_market_cap_improved(cell_text)
                                if parsed_cap > 0:
                                    return parsed_cap

            # ë°©ë²• 3: í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ê²€ìƒ‰
            page_text = soup.get_text()
            market_cap_patterns = [
                r'ì‹œê°€ì´ì•¡[:\s]*([0-9,]+(?:\.[0-9]+)?)\s*([ì¡°ì–µë§Œ]?)ì›?',
                r'ì‹œê°€ì´ì•¡.*?([0-9,]+(?:\.[0-9]+)?)\s*([ì¡°ì–µë§Œ])',
            ]

            for pattern in market_cap_patterns:
                matches = re.findall(pattern, page_text)
                for match in matches:
                    if len(match) >= 2:
                        number_str = match[0].replace(',', '')
                        unit = match[1]
                        try:
                            number = float(number_str)
                            if unit == 'ì¡°':
                                return int(number * 1_000_000_000_000)
                            elif unit == 'ì–µ':
                                return int(number * 100_000_000)
                            elif unit == 'ë§Œ':
                                return int(number * 10_000)
                        except:
                            continue

            return 0

        except Exception as e:
            print(f"âš ï¸ ì‹œê°€ì´ì•¡ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return 0

    def _parse_korean_market_cap_improved(self, market_cap_text):
        """ëŒ€í­ ê°œì„ ëœ í•œêµ­ ì‹œê°€ì´ì•¡ íŒŒì‹±"""
        try:
            if not market_cap_text:
                return 0

            # í…ìŠ¤íŠ¸ ì •ë¦¬
            market_cap_text = market_cap_text.replace(',', '').replace('ì›', '').replace('â‚©', '').strip()

            # íŒ¨í„´ ë§¤ì¹­
            patterns = [
                (r'([0-9.]+)\s*ì¡°', 1_000_000_000_000),
                (r'([0-9.]+)\s*ì–µ', 100_000_000),
                (r'([0-9.]+)\s*ë§Œ', 10_000),
                (r'([0-9.]+)T', 1_000_000_000_000),  # ì•¼í›„íŒŒì´ë‚¸ìŠ¤ ì¡° ë‹¨ìœ„
                (r'([0-9.]+)B', 1_000_000_000),      # ì•¼í›„íŒŒì´ë‚¸ìŠ¤ ì‹­ì–µ ë‹¨ìœ„
                (r'([0-9.]+)M', 1_000_000),          # ì•¼í›„íŒŒì´ë‚¸ìŠ¤ ë°±ë§Œ ë‹¨ìœ„
            ]

            for pattern, multiplier in patterns:
                match = re.search(pattern, market_cap_text)
                if match:
                    number = float(match.group(1))
                    return int(number * multiplier)

            # ë‹¨ìˆœ ìˆ«ìì¸ ê²½ìš°
            numbers = re.findall(r'[0-9.]+', market_cap_text)
            if numbers:
                number = float(numbers[0])
                # í•©ë¦¬ì ì¸ ë²”ìœ„ ì²´í¬ (1ì–µ ~ 1000ì¡°)
                if 100_000_000 <= number <= 1_000_000_000_000_000:
                    return int(number)

            return 0

        except Exception as e:
            print(f"âš ï¸ ì‹œê°€ì´ì•¡ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return 0

    def _extract_korean_current_price_improved(self, soup):
        """ê°œì„ ëœ í•œêµ­ ì£¼ì‹ í˜„ì¬ê°€ ì¶”ì¶œ"""
        try:
            # í˜„ì¬ê°€ ì„ íƒìë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
            price_selectors = [
                '.no_today .blind',
                '.today .no_today .blind',
                'em.no_today',
                '.no_today',
                'strong.tah.p11'
            ]

            for selector in price_selectors:
                element = soup.select_one(selector)
                if element:
                    price_text = element.get_text().strip().replace(',', '')
                    try:
                        price = int(float(price_text))
                        if 100 <= price <= 10_000_000:  # í•©ë¦¬ì ì¸ ì£¼ê°€ ë²”ìœ„
                            return price
                    except:
                        continue

            return 0
        except:
            return 0

    def _extract_korean_financial_data_improved(self, soup):
        """ê°œì„ ëœ í•œêµ­ ì£¼ì‹ ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ"""
        try:
            financial_data = {}

            # PER, PBR, ROE ë“± ì¶”ì¶œ
            financial_indicators = ['PER', 'PBR', 'ROE', 'ROA']

            for indicator in financial_indicators:
                elements = soup.find_all(text=re.compile(indicator))
                for element in elements:
                    parent = element.parent
                    if parent:
                        # ë‹¤ìŒ í˜•ì œ ìš”ì†Œì—ì„œ ê°’ ì°¾ê¸°
                        next_elements = parent.find_next_siblings(['em', 'td', 'span'])
                        for next_elem in next_elements:
                            value_text = next_elem.get_text().strip()
                            try:
                                value = float(value_text.replace(',', '').replace('%', ''))
                                financial_data[indicator.lower()] = value
                                break
                            except:
                                continue
                        if indicator.lower() in financial_data:
                            break

            return financial_data
        except:
            return {}

    def _get_empty_stock_info(self, symbol):
        """ë¹ˆ ì£¼ì‹ ì •ë³´ ë°˜í™˜"""
        return {
            'symbol': symbol,
            'name': symbol,
            'sector': '',
            'industry': '',
            'market_cap': 0,
            'current_price': 0,
            'financial_data': {},
            'description': ''
        }

    def _get_empty_korean_stock_info(self, stock_code):
        """ë¹ˆ í•œêµ­ ì£¼ì‹ ì •ë³´ ë°˜í™˜"""
        return {
            'symbol': stock_code,
            'name': stock_code,
            'sector': '',
            'industry': '',
            'market_cap_krw': 0,
            'current_price_krw': 0,
            'financial_data': {},
            'description': ''
        }


class ESGTextAnalyzer:
    """ESG í…ìŠ¤íŠ¸ ë¶„ì„ê¸° (ê°ì • ë¶„ì„ ê°•í™” ë²„ì „)"""

    def __init__(self):
        self.sentiment_analyzer = AdvancedESGSentimentAnalyzer()

        # ESG ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ (ê°œì„ ëœ ë²„ì „)
        self.esg_keywords_weighted = {
            'environmental': {
                # ê³ ê°€ì¤‘ì¹˜ í‚¤ì›Œë“œ
                'high': ['íƒ„ì†Œì¤‘ë¦½', 'carbon neutral', 'ì¬ìƒì—ë„ˆì§€', 'renewable energy',
                        'ì¹œí™˜ê²½', 'green energy', 'ESG', 'sustainability', 'net zero',
                        'clean energy', 'zero emission'],
                # ì¤‘ê°€ì¤‘ì¹˜ í‚¤ì›Œë“œ
                'medium': ['í™˜ê²½', 'environmental', 'ê¸°í›„ë³€í™”', 'climate change',
                          'ë°°í„°ë¦¬', 'battery', 'ì „ê¸°ì°¨', 'electric', 'cleantech'],
                # ì €ê°€ì¤‘ì¹˜ í‚¤ì›Œë“œ
                'low': ['ê·¸ë¦°', 'green', 'ì—ë„ˆì§€', 'energy', 'ì˜¨ì‹¤ê°€ìŠ¤', 'emission']
            },
            'social': {
                'high': ['ì‚¬íšŒì ì±…ì„', 'social responsibility', 'ì¸ê¶Œ', 'human rights',
                        'ë‹¤ì–‘ì„±', 'diversity', 'ESG', 'social impact'],
                'medium': ['ì‚¬íšŒê³µí—Œ', 'ì§€ì—­ì‚¬íšŒ', 'community', 'ì•ˆì „', 'safety',
                          'ë³µì§€', 'welfare', 'fair trade'],
                'low': ['ì‚¬íšŒ', 'social', 'êµìœ¡', 'education', 'ê±´ê°•', 'health']
            },
            'governance': {
                'high': ['ì§€ë°°êµ¬ì¡°', 'governance', 'íˆ¬ëª…ì„±', 'transparency',
                        'ìœ¤ë¦¬ê²½ì˜', 'ethics', 'ESG', 'corporate governance'],
                'medium': ['ì»´í”Œë¼ì´ì–¸ìŠ¤', 'compliance', 'ê°ì‚¬', 'audit',
                          'ì´ì‚¬íšŒ', 'board', 'board independence'],
                'low': ['ê³µì •ì„±', 'fairness', 'ì±…ì„', 'accountability']
            }
        }

        # ê°€ì¤‘ì¹˜ ê°’
        self.weight_values = {'high': 3.0, 'medium': 2.0, 'low': 1.0}

        print("âœ… ESG í…ìŠ¤íŠ¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ê°ì • ë¶„ì„ ê°•í™”)")

    def calculate_esg_score_from_news(self, news_list):
        """ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ì—ì„œ ESG ì ìˆ˜ ê³„ì‚° (ê°ì • ë¶„ì„ í¬í•¨)"""
        if not news_list:
            return {
                'total_esg_score': 0.0,
                'environmental_score': 0.0,
                'social_score': 0.0,
                'governance_score': 0.0,
                'environmental_count': 0,
                'social_count': 0,
                'governance_count': 0,
                'esg_keyword_count': 0,
                'is_esg_relevant': False,
                'esg_news_count': len(news_list),
                'detailed_analysis': {},
                'sentiment_analysis': {},
                'esg_quality_decision': 'neutral'
            }

        # 1. ê¸°ì¡´ ESG í‚¤ì›Œë“œ ë¶„ì„
        combined_text = ""
        for news in news_list:
            title = news.get('title', '')
            content = news.get('content', '')
            combined_text += f" {title} {content}"

        combined_text = combined_text.lower()

        # ì¹´í…Œê³ ë¦¬ë³„ ê°€ì¤‘ ì ìˆ˜ ê³„ì‚° ë° ê°œìˆ˜ ì„¸ê¸°
        category_scores = {}
        category_details = {}
        category_counts = {}
        total_keyword_count = 0

        for category, weight_groups in self.esg_keywords_weighted.items():
            category_score = 0.0
            category_keywords = 0
            category_count = 0
            keyword_details = {}

            for weight_level, keywords in weight_groups.items():
                weight_value = self.weight_values[weight_level]

                for keyword in keywords:
                    count = combined_text.count(keyword.lower())
                    if count > 0:
                        keyword_details[keyword] = count
                        category_keywords += count
                        category_score += count * weight_value
                        total_keyword_count += count
                        category_count += count

            # ì •ê·œí™” (ìµœëŒ€ê°’ 1.0)
            category_scores[f'{category}_score'] = min(category_score / 10.0, 1.0)
            category_counts[f'{category}_count'] = category_count
            category_details[category] = {
                'score': category_scores[f'{category}_score'],
                'keyword_count': category_keywords,
                'keywords_found': keyword_details,
                'count': category_count
            }

        # 2. ê°ì • ë¶„ì„ ì‹¤í–‰
        sentiment_analysis = self.sentiment_analyzer.analyze_comprehensive_sentiment(news_list)

        # 3. ê°ì • ê¸°ë°˜ ESG í’ˆì§ˆ ê²°ì •
        esg_quality_decision = self._determine_esg_quality(sentiment_analysis, total_keyword_count, len(news_list))

        # 4. ì „ì²´ ESG ì ìˆ˜ ê³„ì‚° (ê°ì • ë¶„ì„ ë°˜ì˜)
        base_esg_score = (
            category_scores.get('environmental_score', 0) +
            category_scores.get('social_score', 0) +
            category_scores.get('governance_score', 0)
        ) / 3

        # ê°ì • ë¶„ì„ ê²°ê³¼ë¡œ ì ìˆ˜ ì¡°ì •
        sentiment_modifier = self._calculate_sentiment_modifier(sentiment_analysis, esg_quality_decision)
        total_esg_score = base_esg_score * sentiment_modifier

        # ESG ê´€ë ¨ì„± íŒë‹¨ (ê°•í™”ëœ ê¸°ì¤€)
        is_esg_relevant = self._is_esg_relevant_enhanced(
            total_keyword_count, len(news_list), sentiment_analysis, esg_quality_decision
        )

        return {
            'total_esg_score': min(total_esg_score, 1.0),
            'environmental_score': category_scores.get('environmental_score', 0),
            'social_score': category_scores.get('social_score', 0),
            'governance_score': category_scores.get('governance_score', 0),
            'environmental_count': category_counts.get('environmental_count', 0),
            'social_count': category_counts.get('social_count', 0),
            'governance_count': category_counts.get('governance_count', 0),
            'esg_keyword_count': total_keyword_count,
            'is_esg_relevant': is_esg_relevant,
            'esg_news_count': len(news_list),
            'detailed_analysis': category_details,
            'sentiment_analysis': sentiment_analysis,
            'esg_quality_decision': esg_quality_decision,
            'sentiment_modifier': sentiment_modifier
        }

    def _determine_esg_quality(self, sentiment_analysis, keyword_count, news_count):
        """ê°ì • ë¶„ì„ ê¸°ë°˜ ESG í’ˆì§ˆ ê²°ì •"""
        sentiment_score = sentiment_analysis.get('sentiment_score', 0.0)
        materiality_score = sentiment_analysis.get('materiality_score', 0.0)
        negative_ratio = sentiment_analysis.get('negative_ratio', 0.0)

        # ë¶€ì •ì  ESG ë‰´ìŠ¤ íŒë‹¨ ê¸°ì¤€ (ê°•í™”ëœ ë²„ì „)
        if (sentiment_score < -0.25 and materiality_score > 0.3 and news_count >= 2) or negative_ratio > 0.6:
            return 'negative'  # ë¶€ì •ì  ESG
        elif sentiment_score > 0.25 and materiality_score > 0.3 and keyword_count >= 3:
            return 'positive'  # ê¸ì •ì  ESG
        else:
            return 'neutral'   # ì¤‘ë¦½ì  ESG

    def _calculate_sentiment_modifier(self, sentiment_analysis, esg_quality_decision):
        """ê°ì • ë¶„ì„ ê¸°ë°˜ ì ìˆ˜ ì¡°ì • ê³„ìˆ˜"""
        if esg_quality_decision == 'negative':
            return 0.3  # ë¶€ì •ì  ESGëŠ” ì ìˆ˜ë¥¼ í¬ê²Œ ê°ì†Œ
        elif esg_quality_decision == 'positive':
            return 1.2  # ê¸ì •ì  ESGëŠ” ì ìˆ˜ë¥¼ ì¦ê°€
        else:
            return 1.0  # ì¤‘ë¦½ì  ESGëŠ” ë³€í™” ì—†ìŒ

    def _is_esg_relevant_enhanced(self, keyword_count, news_count, sentiment_analysis, esg_quality_decision):
        """ê°•í™”ëœ ESG ê´€ë ¨ì„± íŒë‹¨ - SASB ê¸°ì¤€ ì ìš©"""
        # ê¸°ë³¸ ì¡°ê±´: í‚¤ì›Œë“œì™€ ë‰´ìŠ¤ê°€ ì¶©ë¶„í•´ì•¼ í•¨ (ê°•í™”ëœ ê¸°ì¤€)
        has_esg_keywords = keyword_count >= 3  # ìµœì†Œ 3ê°œ í‚¤ì›Œë“œ
        has_esg_news = news_count >= 3  # ìµœì†Œ 3ê°œ ë‰´ìŠ¤

        # ì¬ë£Œì„± ì ìˆ˜ í™•ì¸ (SASB ê¸°ì¤€ ê°•í™”)
        materiality_score = sentiment_analysis.get('materiality_score', 0.0)
        is_material = materiality_score >= 0.5  # 0.2 â†’ 0.5ë¡œ ê°•í™”

        # ë¶€ì •ì  ESGì˜ ê²½ìš° ë” ì—„ê²©í•œ ê¸°ì¤€
        if esg_quality_decision == 'negative':
            return has_esg_keywords and has_esg_news and is_material and news_count >= 3
        else:
            return has_esg_keywords and has_esg_news and is_material


class AdvancedESGSentimentAnalyzer:
    """ê³ ë„í™”ëœ ESG ê°ì • ë¶„ì„ê¸°"""

    def __init__(self):
        try:
            self.vader_analyzer = SentimentIntensityAnalyzer()
        except:
            self.vader_analyzer = None

        # ê¸ˆìœµ íŠ¹í™” ê°ì • í‚¤ì›Œë“œ ì‚¬ì „ (ê°€ì¤‘ì¹˜ í¬í•¨)
        self.financial_sentiment_keywords = {
            'positive': {
                'high': ['ì„±ì¥', 'growth', 'ìˆ˜ìµ', 'profit', 'ì„±ê³µ', 'success', 'í˜ì‹ ', 'innovation',
                        'ê°œì„ ', 'improvement', 'í™•ëŒ€', 'expansion', 'ì¦ê°€', 'increase', 'ê°•í™”', 'strengthen'],
                'medium': ['ì•ˆì •', 'stable', 'ì§€ì†', 'sustainable', 'íš¨ê³¼', 'effective', 'ê¸ì •', 'positive',
                          'ìš°ìˆ˜', 'excellent', 'í–¥ìƒ', 'enhance'],
                'low': ['ì¢‹ì€', 'good', 'ê³„íš', 'plan', 'ëª©í‘œ', 'target']
            },
            'negative': {
                'high': ['ìŠ¤ìº”ë“¤', 'scandal', 'ìœ„ë°˜', 'violation', 'ì‚¬ê¸°', 'fraud', 'ì˜¤ì—¼', 'pollution',
                        'ë²Œê¸ˆ', 'fine', 'ì†Œì†¡', 'lawsuit', 'ì†ì‹¤', 'loss', 'ê°ì†Œ', 'decrease', 'ìœ„í—˜', 'risk'],
                'medium': ['ë¬¸ì œ', 'problem', 'ìš°ë ¤', 'concern', 'ë¹„íŒ', 'criticism', 'ì‹¤íŒ¨', 'failure',
                          'ì§€ì—°', 'delay', 'í•˜ë½', 'decline'],
                'low': ['ì–´ë ¤ì›€', 'difficulty', 'ë„ì „', 'challenge', 'ë¶€ì¡±', 'lack']
            }
        }

        # ESG íŠ¹í™” ë¶€ì • í‚¤ì›Œë“œ (ê°•í™”ëœ ë²„ì „)
        self.esg_negative_keywords = [
            # í™˜ê²½ ê´€ë ¨ ë¶€ì •
            'í™˜ê²½ì˜¤ì—¼', 'pollution', 'ë°°ì¶œê°€ìŠ¤', 'emission violation', 'í™˜ê²½íŒŒê´´', 'environmental damage',
            'ë…ì„±ë¬¼ì§ˆ', 'toxic', 'ê¸°í›„ë³€í™” ëŒ€ì‘ ë¶€ì¡±', 'climate inaction', 'ì¬ìƒì—ë„ˆì§€ ë¶€ì¡±', 'renewable shortfall',

            # ì‚¬íšŒ ê´€ë ¨ ë¶€ì •
            'ë…¸ë™ì°©ì·¨', 'labor exploitation', 'ì¸ê¶Œì¹¨í•´', 'human rights violation', 'ì°¨ë³„', 'discrimination',
            'ë…¸ë™ìŸì˜', 'labor dispute', 'ì•ˆì „ì‚¬ê³ ', 'safety accident', 'ê·¼ë¡œì¡°ê±´ ì•…í™”', 'poor working conditions',

            # ì§€ë°°êµ¬ì¡° ê´€ë ¨ ë¶€ì •
            'ë¶€íŒ¨', 'corruption', 'íš¡ë ¹', 'embezzlement', 'ë°°ì„', 'breach of trust', 'ë¶ˆê³µì •ê±°ë˜', 'unfair trade',
            'ì •ë³´ì€ë‹‰', 'information hiding', 'ì£¼ì£¼ê¶Œìµ ì¹¨í•´', 'shareholder rights violation'
        ]

        print("âœ… ê³ ë„í™”ëœ ESG ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    def analyze_comprehensive_sentiment(self, news_list):
        """ì¢…í•©ì ì¸ ESG ë‰´ìŠ¤ ê°ì • ë¶„ì„"""
        if not news_list:
            return {
                'overall_sentiment': 'neutral',
                'sentiment_score': 0.0,
                'confidence': 0.0,
                'positive_ratio': 0.0,
                'negative_ratio': 0.0,
                'neutral_ratio': 1.0,
                'total_news': 0,
                'sentiment_distribution': [],
                'materiality_score': 0.0,
                'esg_quality_score': 0.0
            }

        sentiment_scores = []
        sentiment_details = []

        for news in news_list:
            title = news.get('title', '')
            content = news.get('content', '')
            combined_text = f"{title} {content}"

            # ê°œë³„ ë‰´ìŠ¤ ê°ì • ë¶„ì„
            individual_sentiment = self._analyze_individual_sentiment(combined_text)
            sentiment_scores.append(individual_sentiment['compound_score'])
            sentiment_details.append(individual_sentiment)

        # ì „ì²´ ê°ì • ì ìˆ˜ ê³„ì‚°
        avg_sentiment = np.mean(sentiment_scores) if sentiment_scores else 0.0
        sentiment_std = np.std(sentiment_scores) if len(sentiment_scores) > 1 else 0.0

        # ê°ì • ë¶„í¬ ê³„ì‚°
        positive_count = sum(1 for score in sentiment_scores if score > 0.1)
        negative_count = sum(1 for score in sentiment_scores if score < -0.1)
        neutral_count = len(sentiment_scores) - positive_count - negative_count

        total_news = len(news_list)
        positive_ratio = positive_count / total_news if total_news > 0 else 0
        negative_ratio = negative_count / total_news if total_news > 0 else 0
        neutral_ratio = neutral_count / total_news if total_news > 0 else 1

        # ì¬ë£Œì„± ì ìˆ˜ (ë‰´ìŠ¤ ìˆ˜ì™€ ì¼ê´€ì„± ê¸°ë°˜)
        materiality_score = self._calculate_materiality_score(total_news, sentiment_std)

        # ESG í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        esg_quality_score = self._calculate_esg_quality_score(
            avg_sentiment, total_news, sentiment_std, positive_ratio, negative_ratio
        )

        # ì „ì²´ ê°ì • ê²°ì •
        if avg_sentiment > 0.25 and materiality_score > 0.3:
            overall_sentiment = 'positive'
        elif avg_sentiment < -0.25 and materiality_score > 0.3:
            overall_sentiment = 'negative'
        else:
            overall_sentiment = 'neutral'

        return {
            'overall_sentiment': overall_sentiment,
            'sentiment_score': avg_sentiment,
            'confidence': materiality_score,
            'positive_ratio': positive_ratio,
            'negative_ratio': negative_ratio,
            'neutral_ratio': neutral_ratio,
            'total_news': total_news,
            'sentiment_distribution': sentiment_details,
            'materiality_score': materiality_score,
            'esg_quality_score': esg_quality_score,
            'sentiment_std': sentiment_std
        }

    def _analyze_individual_sentiment(self, text):
        """ê°œë³„ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ (ê°•í™”ëœ ë²„ì „)"""
        if not text:
            return {'compound_score': 0.0, 'method': 'empty'}

        text_lower = text.lower()

        # 1. VADER ë¶„ì„
        vader_score = 0.0
        if self.vader_analyzer:
            try:
                vader_result = self.vader_analyzer.polarity_scores(text)
                vader_score = vader_result['compound']
            except:
                vader_score = 0.0

        # 2. TextBlob ë¶„ì„
        textblob_score = 0.0
        try:
            blob = TextBlob(text)
            textblob_score = blob.sentiment.polarity
        except:
            textblob_score = 0.0

        # 3. ê¸ˆìœµ íŠ¹í™” í‚¤ì›Œë“œ ë¶„ì„
        financial_score = self._calculate_financial_keyword_sentiment(text_lower)

        # 4. ESG ë¶€ì • í‚¤ì›Œë“œ íŒ¨ë„í‹°
        esg_negative_penalty = self._calculate_esg_negative_penalty(text_lower)

        # 5. ê°€ì¤‘ í‰ê·  ê³„ì‚°
        base_score = (vader_score * 0.4 + textblob_score * 0.3 + financial_score * 0.3)
        final_score = base_score + esg_negative_penalty

        # ì ìˆ˜ ì •ê·œí™” (-1 ~ 1)
        final_score = max(-1.0, min(1.0, final_score))

        return {
            'compound_score': final_score,
            'vader_score': vader_score,
            'textblob_score': textblob_score,
            'financial_score': financial_score,
            'esg_penalty': esg_negative_penalty,
            'method': 'comprehensive'
        }

    def _calculate_financial_keyword_sentiment(self, text):
        """ê¸ˆìœµ íŠ¹í™” í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ì ìˆ˜"""
        positive_score = 0.0
        negative_score = 0.0

        # ê¸ì • í‚¤ì›Œë“œ ì ìˆ˜
        for weight_level, keywords in self.financial_sentiment_keywords['positive'].items():
            multiplier = {'high': 1.0, 'medium': 0.7, 'low': 0.4}[weight_level]
            for keyword in keywords:
                count = text.count(keyword.lower())
                positive_score += count * multiplier

        # ë¶€ì • í‚¤ì›Œë“œ ì ìˆ˜
        for weight_level, keywords in self.financial_sentiment_keywords['negative'].items():
            multiplier = {'high': 1.0, 'medium': 0.7, 'low': 0.4}[weight_level]
            for keyword in keywords:
                count = text.count(keyword.lower())
                negative_score += count * multiplier

        # ì •ê·œí™” ë° ìµœì¢… ì ìˆ˜
        if positive_score + negative_score == 0:
            return 0.0

        net_score = (positive_score - negative_score) / (positive_score + negative_score + 1)
        return max(-0.5, min(0.5, net_score))

    def _calculate_esg_negative_penalty(self, text):
        """ESG ë¶€ì • í‚¤ì›Œë“œ íŒ¨ë„í‹°"""
        penalty = 0.0

        for keyword in self.esg_negative_keywords:
            if keyword.lower() in text:
                penalty -= 0.2  # ë¶€ì • í‚¤ì›Œë“œë‹¹ -0.2 íŒ¨ë„í‹°

        return max(-0.8, penalty)  # ìµœëŒ€ -0.8ê¹Œì§€ íŒ¨ë„í‹°

    def _calculate_materiality_score(self, news_count, sentiment_std):
        """ì¬ë£Œì„± ì ìˆ˜ ê³„ì‚° (ë‰´ìŠ¤ ìˆ˜ì™€ ì¼ê´€ì„± ê¸°ë°˜) - SASB ê¸°ì¤€ ê°•í™”"""
        # ë‰´ìŠ¤ ìˆ˜ ê¸°ë°˜ ì ìˆ˜ (3ê°œ ì´ìƒì—ì„œ ì‹œì‘, 5ê°œ ì´ìƒì—ì„œ ìœ ì˜ë¯¸)
        if news_count >= 5:
            news_score = 1.0
        elif news_count >= 3:
            news_score = 0.6
        elif news_count >= 2:
            news_score = 0.3
        else:
            news_score = 0.0

        # ê°ì • ì¼ê´€ì„± ì ìˆ˜ (í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
        consistency_score = max(0, 1.0 - sentiment_std) if sentiment_std > 0 else 0.5

        return (news_score * 0.8 + consistency_score * 0.2)

    def _calculate_esg_quality_score(self, avg_sentiment, news_count, sentiment_std, positive_ratio, negative_ratio):
        """ESG í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        # ê¸°ë³¸ ì ìˆ˜
        base_score = 0.5

        # ê°ì • ê°•ë„ ë³´ë„ˆìŠ¤
        sentiment_intensity = abs(avg_sentiment)
        if sentiment_intensity > 0.3:
            base_score += 0.2

        # ë‰´ìŠ¤ ìˆ˜ ë³´ë„ˆìŠ¤
        if news_count >= 3:
            base_score += 0.1
        if news_count >= 5:
            base_score += 0.1

        # ê°ì • ë¶„í¬ ê· í˜• ì ìˆ˜
        if 0.2 <= positive_ratio <= 0.8 and 0.2 <= negative_ratio <= 0.8:
            base_score += 0.1  # ê· í˜•ì¡íŒ ë¶„í¬

        return min(1.0, base_score)

class WebScrapingNewsCollector:
    """ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""

    def __init__(self):
        self.session = requests.Session()
        
        # User-Agent í—¤ë” ì„¤ì •
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0'
        ]
        
        self._update_headers()
        print("âœ… ì›¹ í¬ë¡¤ë§ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    def _update_headers(self):
        """í—¤ë” ì—…ë°ì´íŠ¸"""
        user_agent = random.choice(self.user_agents)
        self.session.headers.update({
            'User-Agent': user_agent,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })

    def collect_comprehensive_news(self, stock_code, company_name):
        """ì¢…í•©ì ì¸ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        try:
            print(f"ğŸ“° {company_name} ESG ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
            
            all_news = []
            
            # êµ¬ê¸€ ë‰´ìŠ¤ì—ì„œ ESG ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘
            google_news = self._collect_google_news(stock_code, company_name)
            all_news.extend(google_news)
            
            # ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ìˆ˜ì§‘ (í•œêµ­ ì£¼ì‹ì¸ ê²½ìš°)
            if re.match(r'^\d{6}$', stock_code):
                naver_news = self._collect_naver_news(stock_code, company_name)
                all_news.extend(naver_news)
            
            # ì¤‘ë³µ ì œê±°
            unique_news = self._remove_duplicates(all_news)
            
            print(f"âœ… {company_name} ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(unique_news)}ê°œ")
            return unique_news[:10]  # ìµœëŒ€ 10ê°œ ë‰´ìŠ¤ë§Œ ë°˜í™˜
            
        except Exception as e:
            print(f"âŒ {company_name} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    def _collect_google_news(self, stock_code, company_name):
        """êµ¬ê¸€ ë‰´ìŠ¤ì—ì„œ ESG ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        try:
            news_list = []
            
            # ESG ê´€ë ¨ ê²€ìƒ‰ì–´
            search_terms = [
                f"{company_name} ESG",
                f"{company_name} í™˜ê²½",
                f"{company_name} ì§€ì†ê°€ëŠ¥",
                f"{stock_code} ESG"
            ]
            
            for term in search_terms[:2]:  # ì²˜ìŒ 2ê°œë§Œ ì‚¬ìš©
                try:
                    encoded_term = quote(term)
                    url = f"https://news.google.com/rss/search?q={encoded_term}&hl=ko&gl=KR&ceid=KR:ko"
                    
                    response = self.session.get(url, timeout=10)
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.content, 'xml')
                        items = soup.find_all('item')[:3]  # ê° ê²€ìƒ‰ì–´ë‹¹ ìµœëŒ€ 3ê°œ
                        
                        for item in items:
                            try:
                                title = item.title.text if item.title else ""
                                link = item.link.text if item.link else ""
                                pub_date = item.pubDate.text if item.pubDate else ""
                                description = item.description.text if item.description else ""
                                
                                if title and self._is_esg_related(title + " " + description):
                                    news_list.append({
                                        'title': title,
                                        'content': description,
                                        'url': link,
                                        'date': pub_date,
                                        'source': 'Google News'
                                    })
                            except:
                                continue
                    
                    time.sleep(1)  # ìš”ì²­ ê°„ê²©
                except:
                    continue
            
            return news_list
            
        except Exception as e:
            print(f"âš ï¸ êµ¬ê¸€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    def _collect_naver_news(self, stock_code, company_name):
        """ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ìˆ˜ì§‘"""
        try:
            news_list = []
            
            # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰
            search_term = f"{company_name} ESG"
            encoded_term = quote(search_term)
            url = f"https://search.naver.com/search.naver?where=news&query={encoded_term}"
            
            response = self.session.get(url, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ë‰´ìŠ¤ í•­ëª© ì°¾ê¸°
                news_items = soup.find_all('div', class_='news_area')[:5]  # ìµœëŒ€ 5ê°œ
                
                for item in news_items:
                    try:
                        title_elem = item.find('a', class_='news_tit')
                        if title_elem:
                            title = title_elem.get_text().strip()
                            link = title_elem.get('href', '')
                            
                            # ìš”ì•½ í…ìŠ¤íŠ¸
                            content_elem = item.find('div', class_='news_dsc')
                            content = content_elem.get_text().strip() if content_elem else ""
                            
                            if self._is_esg_related(title + " " + content):
                                news_list.append({
                                    'title': title,
                                    'content': content,
                                    'url': link,
                                    'date': '',
                                    'source': 'Naver News'
                                })
                    except:
                        continue
            
            return news_list
            
        except Exception as e:
            print(f"âš ï¸ ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    def _is_esg_related(self, text):
        """ESG ê´€ë ¨ ë‰´ìŠ¤ì¸ì§€ íŒë‹¨"""
        esg_keywords = [
            'ESG', 'í™˜ê²½', 'ì§€ì†ê°€ëŠ¥', 'íƒ„ì†Œì¤‘ë¦½', 'ì¹œí™˜ê²½', 'ì¬ìƒì—ë„ˆì§€',
            'ì‚¬íšŒì ì±…ì„', 'ì§€ë°°êµ¬ì¡°', 'ìœ¤ë¦¬ê²½ì˜', 'íˆ¬ëª…ì„±', 'ì»´í”Œë¼ì´ì–¸ìŠ¤',
            'environmental', 'social', 'governance', 'sustainability',
            'carbon neutral', 'renewable energy', 'green energy'
        ]
        
        text_lower = text.lower()
        return any(keyword.lower() in text_lower for keyword in esg_keywords)

    def _remove_duplicates(self, news_list):
        """ì¤‘ë³µ ë‰´ìŠ¤ ì œê±°"""
        seen_titles = set()
        unique_news = []
        
        for news in news_list:
            title = news.get('title', '').strip()
            if title and title not in seen_titles:
                seen_titles.add(title)
                unique_news.append(news)
        
        return unique_news

    def safe_request(self, url, max_retries=3):
        """ì•ˆì „í•œ ì›¹ ìš”ì²­"""
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    self._update_headers()
                    time.sleep(random.uniform(2, 5))
                
                response = self.session.get(url, timeout=15)
                if response.status_code == 200:
                    return response
                else:
                    print(f"âš ï¸ HTTP {response.status_code} - ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                    time.sleep(random.uniform(3, 6))
                    
            except requests.exceptions.RequestException as e:
                print(f"âš ï¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e} - ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                time.sleep(random.uniform(5, 10))
        
        return None



# ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ ìˆ˜ì • (ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±°)
class WebScrapingStockDataCollector:
    """ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ê¸° - ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±° ë²„ì „"""

    def __init__(self):
        self.news_collector = WebScrapingNewsCollector()
        self.esg_analyzer = ESGTextAnalyzer()
        self.currency_converter = WebScrapingCurrencyConverter()
        self.yahoo_collector = WebScrapingYahooFinanceCollector()

        print("âœ… ì›¹ í¬ë¡¤ë§ ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±°)")

    def collect_stock_data(self, stock_code):
        """ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ - ì™„ì „ ì›¹ í¬ë¡¤ë§ ë²„ì „"""
        print(f"\nğŸ” ì¢…ëª© {stock_code} ì›¹ í¬ë¡¤ë§ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘... (API ì—†ìŒ)")

        if self.is_korean_stock(stock_code):
            return self._collect_korean_stock_data(stock_code)
        else:
            return self._collect_overseas_stock_data(stock_code)

    def is_korean_stock(self, stock_code):
        """êµ­ë‚´ì£¼ì‹ ì—¬ë¶€ íŒë‹¨"""
        return re.match(r'^\d{6}$', stock_code) is not None

    def _collect_korean_stock_data(self, stock_code):
        """êµ­ë‚´ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ - ì›¹ í¬ë¡¤ë§ë§Œ ì‚¬ìš©"""
        try:
            # ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
            basic_info = self.yahoo_collector.scrape_korean_stock_info(stock_code)
            company_name = basic_info.get('name', f'ì¢…ëª©{stock_code}')

            # ì‹œê°€ì´ì•¡ì„ ë‹¬ëŸ¬ë¡œ ë³€í™˜
            market_cap_krw = basic_info.get('market_cap_krw', 0)
            market_cap_usd = self.currency_converter.krw_to_usd(market_cap_krw)

            # ê¸°ë³¸ ì •ë³´ ì—…ë°ì´íŠ¸
            basic_info.update({
                'market_cap_usd': market_cap_usd,
                'market_cap': market_cap_usd,
                'currency': 'USD'
            })

            print(f"ğŸ¢ {company_name} | ì—…ì¢…: {basic_info.get('sector', 'ì •ë³´ì—†ìŒ')} | ì‹œê°€ì´ì•¡: ${market_cap_usd:,.0f}")

            # ESG ë‰´ìŠ¤ ìˆ˜ì§‘
            esg_news = self.news_collector.collect_comprehensive_news(stock_code, company_name)

            # ESG ë¶„ì„
            esg_analysis = self.esg_analyzer.calculate_esg_score_from_news(esg_news)

            # ì¬ë¬´ ì •ë³´
            financial_data = basic_info.get('financial_data', {})

            print(f"âœ… {company_name} êµ­ë‚´ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ì‹œê°€ì´ì•¡: ${market_cap_usd:,.0f})")

            return {
                'stock_code': stock_code,
                'basic_info': basic_info,
                'esg_news': esg_news,
                'esg_analysis': esg_analysis,
                'financial_data': financial_data,
                'source': 'korean_webscraping_no_api'
            }

        except Exception as e:
            print(f"âŒ {stock_code} êµ­ë‚´ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return self._get_empty_data(stock_code)

    def _collect_overseas_stock_data(self, stock_code):
        """í•´ì™¸ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ - ì›¹ í¬ë¡¤ë§ë§Œ ì‚¬ìš©"""
        try:
            # ì•¼í›„íŒŒì´ë‚¸ìŠ¤ ì›¹ í¬ë¡¤ë§ìœ¼ë¡œ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
            basic_info = self.yahoo_collector.scrape_stock_info(stock_code)
            company_name = basic_info.get('name', stock_code)
            market_cap_usd = basic_info.get('market_cap', 0)

            # ê¸°ë³¸ ì •ë³´ ì—…ë°ì´íŠ¸
            basic_info.update({
                'stock_code': stock_code,
                'market_cap_usd': market_cap_usd,
                'market_cap_krw': 0,
                'currency': 'USD'
            })

            print(f"ğŸ¢ {company_name} | ì—…ì¢…: {basic_info.get('sector', 'ì •ë³´ì—†ìŒ')} | ì‹œê°€ì´ì•¡: ${market_cap_usd:,.0f}")

            # ESG ë‰´ìŠ¤ ìˆ˜ì§‘
            esg_news = self.news_collector.collect_comprehensive_news(stock_code, company_name)

            # ESG ë¶„ì„
            esg_analysis = self.esg_analyzer.calculate_esg_score_from_news(esg_news)

            # ì¬ë¬´ ë°ì´í„°
            financial_data = basic_info.get('financial_data', {})

            print(f"âœ… {company_name} í•´ì™¸ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ì‹œê°€ì´ì•¡: ${market_cap_usd:,.0f})")

            return {
                'stock_code': stock_code,
                'basic_info': basic_info,
                'esg_news': esg_news,
                'esg_analysis': esg_analysis,
                'financial_data': financial_data,
                'source': 'overseas_webscraping_no_api'
            }

        except Exception as e:
            print(f"âŒ {stock_code} í•´ì™¸ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return self._get_empty_data(stock_code)

    def _get_empty_data(self, stock_code):
        """ë¹ˆ ë°ì´í„° êµ¬ì¡°"""
        return {
            'stock_code': stock_code,
            'basic_info': {'name': stock_code, 'sector': '', 'market_cap_usd': 0, 'currency': 'USD'},
            'esg_news': [],
            'esg_analysis': {
                'total_esg_score': 0.0,
                'is_esg_relevant': False,
                'esg_news_count': 0,
                'esg_quality_decision': 'neutral'
            },
            'financial_data': {},
            'source': 'empty'
        }

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ì—…ë°ì´íŠ¸
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±° ë²„ì „)"""
    print("ğŸš€ ì›¹ í¬ë¡¤ë§ ê¸°ë°˜ ESG ì£¼ì‹ ë¶„ì„ ì‹œìŠ¤í…œ v6.5 (ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±°)")
    print("=" * 90)
    print("ğŸŒ ë°ì´í„° ì†ŒìŠ¤: ë„¤ì´ë²„ ê¸ˆìœµ, ì•¼í›„íŒŒì´ë‚¸ìŠ¤ ì›¹í˜ì´ì§€, êµ¬ê¸€ ë‰´ìŠ¤ (100% ì›¹ í¬ë¡¤ë§)")
    print("ğŸ”‘ ì™¸ë¶€ API í‚¤ ì™„ì „ ë¶ˆí•„ìš” - ìˆœìˆ˜ ì›¹ í¬ë¡¤ë§ ì†”ë£¨ì…˜")
    print("ğŸ’± ëª¨ë“  ë¶„ì„ì´ ë‹¬ëŸ¬ ê¸°ì¤€ìœ¼ë¡œ í†µì¼ë©ë‹ˆë‹¤")
    print("ğŸ­ ê°ì • ë¶„ì„ìœ¼ë¡œ ë¶€ì •ì  ESG ë‰´ìŠ¤ í•„í„°ë§")

    # ë¶„ì„í•  í¬íŠ¸í´ë¦¬ì˜¤
    portfolio_stocks = [
        '096770',  # SKì´ë…¸ë² ì´ì…˜
        '304780',  # í¬ìŠ¤ì½”í™€ë”©ìŠ¤
        '000810',  # ì‚¼ì„±í™”ì¬
        'AAPL',    # Apple
        'TSLA',    # Tesla
        'NVDA'     # NVIDIA
    ]

    # ë¹„ì¤‘ ì„¤ì •
    raw_weights = [20, 15, 15, 20, 15, 15]
    total = sum(raw_weights)
    weights = [w / total for w in raw_weights]

    try:
        # ì›¹ í¬ë¡¤ë§ ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (API ì œê±°)
        analyzer = WebScrapingStockAnalysisSystem(risk_profile='ì¤‘ë¦½')

        # í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ì‹¤í–‰
        analysis_result = analyzer.analyze_portfolio(portfolio_stocks, weights)

        # ë¶„ì„ ë¦¬í¬íŠ¸ ì¶œë ¥
        print_analysis_report(analysis_result)

        print(f"\nâœ… ì•¼í›„íŒŒì´ë‚¸ìŠ¤ API ì œê±° ë¶„ì„ ì™„ë£Œ! (100% ì›¹ í¬ë¡¤ë§)")
        print("=" * 90)

    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()

# if __name__ == "__main__":
#     main()
